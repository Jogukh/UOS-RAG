#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê±´ì¶• ë„ë©´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° í”„ë¡œì íŠ¸ ë¶„ì„ ë„êµ¬ (LLM ê¸°ë°˜)
- PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- LLM ê¸°ë°˜ ë„ë©´ ì •ë³´ ë©”íƒ€ë°ì´í„° ìƒì„±
- í”„ë¡œì íŠ¸ ë‹¨ìœ„ ë„ë©´ ê´€ê³„ ë¶„ì„
"""

import json
import os
import re
import io
import sys
from datetime import datetime
from pathlib import Path
import fitz  # PyMuPDF
from pypdf import PdfReader # PyPDF2 ëŒ€ì‹  pypdf ì‚¬ìš© (ìµœì‹  ê¶Œì¥)

# LLM ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° import
sys.path.append(str(Path(__file__).parent / "src"))
try:
    from llm_metadata_extractor import LLMMetadataExtractor
    HAS_LLM_EXTRACTOR = True
except ImportError as e:
    print(f"âš ï¸  LLM ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("   ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ ì¶”ì¶œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    HAS_LLM_EXTRACTOR = False

class ArchitecturalMetadataExtractor:
    def __init__(self, analysis_file="uploads_analysis_results.json", uploads_root_dir="uploads"):
        self.analysis_file = Path(analysis_file) # Path ê°ì²´ë¡œ ë³€ê²½
        self.uploads_root_dir = Path(uploads_root_dir) # Path ê°ì²´ë¡œ ë³€ê²½
        # project_metadataëŠ” í”„ë¡œì íŠ¸ë³„ë¡œ ìƒì„±ë˜ë¯€ë¡œ, í´ë˜ìŠ¤ ë©¤ë²„ì—ì„œ ì œê±°í•˜ê³  process_projectì—ì„œ ë°˜í™˜í•˜ë„ë¡ ë³€ê²½
        
    def load_analysis_results(self):
        """uploads_analysis_results.json íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.analysis_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({self.analysis_file}): {e}")
            return None

    def extract_text_from_pdf_page_content(self, page_text_content):
        """
        analyze_uploads_new.pyì—ì„œ ì´ë¯¸ ì¶”ì¶œëœ í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜,
        í•„ìš”ì‹œ ì¶”ê°€ ì •ì œ ë¡œì§ì„ ì—¬ê¸°ì— êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        í˜„ì¬ëŠ” ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if isinstance(page_text_content, str):
            return page_text_content.strip()
        return ""

    def extract_drawing_metadata_from_text(self, text_content, file_name, page_number, project_path_str):
        """í…ìŠ¤íŠ¸ì—ì„œ ë„ë©´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (VLM ë¶„ì„ ê²°ê³¼ ì—†ì´)"""
        metadata = {
            "file_name": file_name,
            "page_number": page_number,
            "full_path": str(Path(project_path_str) / file_name), # íŒŒì¼ ì „ì²´ ê²½ë¡œ ì¶”ê°€
            "drawing_number": "ê·¼ê±° ë¶€ì¡±",
            "drawing_title": "ê·¼ê±° ë¶€ì¡±", 
            "drawing_type": "ê·¼ê±° ë¶€ì¡±", # drawing_titleê³¼ ìœ ì‚¬í•˜ê²Œ ì„¤ì •ë  ìˆ˜ ìˆìŒ
            "scale": "ê·¼ê±° ë¶€ì¡±",
            "area_info": {},
            "room_list": [],
            "level_info": [], # ì¸µ ì •ë³´
            "dimensions": [], # ì£¼ìš” ì¹˜ìˆ˜
            # "building_info": {}, # í”„ë¡œì íŠ¸ ë ˆë²¨ë¡œ ì´ë™ ê°€ëŠ¥
            # "project_info": {}, # í”„ë¡œì íŠ¸ ë ˆë²¨ë¡œ ì´ë™ ê°€ëŠ¥
            "raw_text_snippet": text_content[:500] + "..." if len(text_content) > 500 else text_content, # ë¯¸ë¦¬ë³´ê¸°ìš© í…ìŠ¤íŠ¸ ì¼ë¶€
            "extracted_at": datetime.now().isoformat()
        }
        
        # ì •ê·œ í‘œí˜„ì‹ íŒ¨í„´ë“¤ (ê¸°ì¡´ ë¡œì§ í™œìš©, í•„ìš”ì‹œ ê°œì„ )
        # ë„ë©´ ë²ˆí˜¸ (Drawing Number)
        # ë³´ë‹¤ ì¼ë°˜ì ì´ê³  ë‹¤ì–‘í•œ í˜•ì‹ì„ í¬ê´„í•˜ë„ë¡ ìˆ˜ì •
        drawing_number_patterns = [
            r"DWG\\.?\\s*NO\\.?\\s*[:\\s]*([A-Z0-9\\-_./]+)",  # DWG. NO. A-001, DWG NO: X-X-001
            r"ë„ë©´ë²ˆí˜¸\\s*[:\\s]*([A-Z0-9\\-_./]+)",          # ë„ë©´ë²ˆí˜¸: ê°€-101
            r"SHEET\\s*NO\\.?\\s*[:\\s]*([A-Z0-9\\-_./]+)",    # SHEET NO. A-100
            r"ë„\\s*ë©´\\s*ëª…\\s*[:\\s]*.*\\(([A-Z0-9\\-_.]+)\\)", # ë„ ë©´ ëª… : XXX í‰ë©´ë„ (A-101)
            r"\\b([A-Z]{1,3}[-\\s]?[0-9]{2,4}[-\\s]?[A-Z0-9]{0,3})\\b", # A-101, AR-001, STR-1001-A (ì¼ë°˜ì ì¸ ë„ë©´ ë²ˆí˜¸ í˜•ì‹)
            r"\\b([A-Z]{1,3}[0-9]{2,4})\\b" # A101, AR001
        ]
        for pattern in drawing_number_patterns:
            match = re.search(pattern, text_content, re.IGNORECASE)
            if match:
                metadata["drawing_number"] = match.group(1).strip() if match.groups() else match.group(0).strip()
                break
        
        # ë„ë©´ ì œëª©/ìœ í˜• (Drawing Title/Type)
        # ì¢€ ë” í¬ê´„ì ì¸ í‚¤ì›Œë“œì™€, ì œëª©ìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆëŠ” ë¼ì¸ íƒìƒ‰
        title_keywords = [
            "í‰ë©´ë„", "ì…ë©´ë„", "ë‹¨ë©´ë„", "ë°°ì¹˜ë„", "ì£¼ë‹¨ë©´ë„", "ì¢…ë‹¨ë©´ë„", "íš¡ë‹¨ë©´ë„",
            "ì°½í˜¸ë„", "ìƒì„¸ë„", "ê³„íšë„", "ì„¤ê³„ë„", "ì „ê°œë„", "êµ¬ì¡°ë„", "ì„¤ë¹„ë„",
            "ì „ê¸°ì„¤ë¹„ë„", "ê¸°ê³„ì„¤ë¹„ë„", "ì†Œë°©ì„¤ë¹„ë„", "í†µì‹ ì„¤ë¹„ë„"
        ]
        # ì œëª©ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ë¼ì¸ (ì˜ˆ: "OOO í‰ë©´ë„", "ì œ1ì¢… ì§€êµ¬ë‹¨ìœ„ê³„íš ê²°ì •ë„")
        # ë³´í†µ í˜ì´ì§€ ìƒë‹¨ì´ë‚˜ íŠ¹ì • ë°•ìŠ¤ ì•ˆì— ìœ„ì¹˜
        lines = text_content.split('\\n')
        found_title = False
        for line in lines[:15]: # ìƒìœ„ 15ì¤„ì—ì„œ íƒìƒ‰
            for keyword in title_keywords:
                if keyword in line:
                    # í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ì „ì²´ ë¼ì¸ ë˜ëŠ” ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ì„ ì œëª©ìœ¼ë¡œ
                    # ì˜ˆ: "ë‹¨ìœ„ì„¸ëŒ€ í‰ë©´ë„ (TYPE 84A)"
                    # ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ, ì£¼ìš” ì •ë³´ë§Œ ì¶”ì¶œ
                    title_candidate = line.strip()
                    # ë„ë©´ë²ˆí˜¸ë‚˜ ì¶•ì²™ ë“± ë‹¤ë¥¸ ì •ë³´ê°€ ì„ì—¬ìˆìœ¼ë©´ ë¶„ë¦¬ ì‹œë„
                    # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ì„ ì‚¬ìš©
                    metadata["drawing_title"] = title_candidate[:100] # ê¸¸ì´ ì œí•œ
                    metadata["drawing_type"] = keyword # í•µì‹¬ í‚¤ì›Œë“œë¥¼ íƒ€ì…ìœ¼ë¡œ
                    found_title = True
                    break
            if found_title:
                break
        
        if not found_title and metadata["drawing_number"] != "ê·¼ê±° ë¶€ì¡±":
             metadata["drawing_title"] = f"{metadata['drawing_number']} ê´€ë ¨ ë„ë©´"


        # ì¶•ì²™ (Scale)
        scale_patterns = [
            r"SCALE\s*[:\s]*([0-9.,]+(?:\s*:\s*[0-9.,]+)?(?:\s*@\s*[A-Z0-9]+)?)", # SCALE : 1/100, SCALE : 1:100, 1/200 @ A3
            r"ì¶•ì²™\s*[:\s]*([0-9.,]+(?:\s*:\s*[0-9.,]+)?(?:\s*@\s*[A-Z0-9]+)?)",   # ì¶•ì²™ : 1/100
            r"\bS\s*=\s*([0-9.,]+/[0-9.,]+)\b", # S = 1/100
            r"\b(1\s*[:/]\s*[0-9.,]+)\b(?:\s*\(?[A-Z][0-9]\)?)?" # 1:100, 1/100, 1/200 (A3)
        ]
        for pattern in scale_patterns:
            match = re.search(pattern, text_content, re.IGNORECASE)
            if match:
                scale_str = match.group(1).strip().replace(" ", "")
                metadata["scale"] = scale_str
                break
        
        # ë©´ì  ì •ë³´ (Area Information) - m2, ã¡, í‰ ë“± ë‹¨ìœ„ ê³ ë ¤
        area_patterns = [
            # ì „ìš©ë©´ì , ê³µê¸‰ë©´ì , ê³„ì•½ë©´ì , ê¸°íƒ€ë©´ì , ë°œì½”ë‹ˆ, ì„œë¹„ìŠ¤ë©´ì  ë“±
            r"(ì „ìš©ë©´ì |ì£¼ê±°ì „ìš©|ì „ìš©)\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ê³µìš©ë©´ì |ì£¼ê±°ê³µìš©|ê³µìš©)\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ê³µê¸‰ë©´ì |ë¶„ì–‘ë©´ì )\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ê³„ì•½ë©´ì )\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ê¸°íƒ€ê³µìš©ë©´ì |ê¸°íƒ€ê³µìš©)\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ë°œì½”ë‹ˆ|ë°œì½”ë‹ˆë©´ì |ì„œë¹„ìŠ¤ë©´ì )\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ëŒ€ì§€ë©´ì )\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ê±´ì¶•ë©´ì )\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
            r"(ì—°ë©´ì |ì´ë©´ì )\s*[:\s]*([0-9.,]+\.?[0-9]*)\s*(ã¡|m2|í‰|M2|MÂ²)",
        ]
        areas = {}
        # ê° ë©´ì  íŒ¨í„´ì„ ê°œë³„ì ìœ¼ë¡œ ê²€ì‚¬
        for pattern in area_patterns:
            matches = re.findall(pattern, text_content, re.IGNORECASE)
            for match in matches:
                if len(match) >= 3:
                    name, val, unit = match[0], match[1], match[2]
                    area_type_map = {
                        "ì „ìš©ë©´ì ": "exclusive_area", "ì£¼ê±°ì „ìš©": "exclusive_area", "ì „ìš©": "exclusive_area",
                        "ê³µìš©ë©´ì ": "public_area", "ì£¼ê±°ê³µìš©": "public_area", "ê³µìš©": "public_area",
                        "ê³µê¸‰ë©´ì ": "supply_area", "ë¶„ì–‘ë©´ì ": "supply_area",
                        "ê³„ì•½ë©´ì ": "contract_area",
                        "ê¸°íƒ€ê³µìš©ë©´ì ": "other_public_area", "ê¸°íƒ€ê³µìš©": "other_public_area",
                        "ë°œì½”ë‹ˆ": "balcony_area", "ë°œì½”ë‹ˆë©´ì ": "balcony_area", "ì„œë¹„ìŠ¤ë©´ì ": "balcony_area",
                        "ëŒ€ì§€ë©´ì ": "site_area", "ê±´ì¶•ë©´ì ": "building_area", "ì—°ë©´ì ": "total_floor_area", "ì´ë©´ì ": "total_floor_area"
                    }
                    # ì •ê·œí™”ëœ í‚¤ì›Œë“œ ì°¾ê¸°
                    normalized_key = ""
                    for k_map, v_map in area_type_map.items():
                        if k_map in name:
                            normalized_key = v_map
                            break
                    if normalized_key:
                        areas[normalized_key] = {"value": val, "unit": unit}
        
        if areas:
            metadata["area_info"] = areas

        # ê³µê°„ ëª©ë¡ (Room List) - ë‹¤ì–‘í•œ í‘œí˜„ ê³ ë ¤
        room_keywords = [
            "ê±°ì‹¤", "ì¹¨ì‹¤[0-9]*", "ì•ˆë°©", "ìë…€ë°©", "ë°©[0-9]*", "ë£¸",
            "ì£¼ë°©", "í‚¤ì¹œ", "ì‹ë‹¹", "ë‹¤ì´ë‹ë£¸",
            "ìš•ì‹¤[0-9]*", "í™”ì¥ì‹¤[0-9]*", "ìƒ¤ì›Œì‹¤", "íŒŒìš°ë”ë£¸",
            "í˜„ê´€", "ì „ì‹¤", "í™€",
            "ë°œì½”ë‹ˆ[0-9]*", "ë² ë€ë‹¤", "í…Œë¼ìŠ¤",
            "ë‹¤ìš©ë„ì‹¤", "ì„¸íƒì‹¤", "ë³´ì¼ëŸ¬ì‹¤",
            "ë“œë ˆìŠ¤ë£¸", "ì˜·ë°©", "ë¶™ë°•ì´ì¥",
            "íŒ¬íŠ¸ë¦¬", "ì°½ê³ ", "ìˆ˜ë‚©ê³µê°„",
            "ì„œì¬", "ì‘ì—…ì‹¤", "ìŠ¤í„°ë””ë£¸",
            "ì•ŒíŒŒë£¸", "ë§˜ìŠ¤ì˜¤í”¼ìŠ¤", "ê°€ì¡±ì‹¤",
            "ëŒ€í”¼ê³µê°„", "ì‹¤ì™¸ê¸°ì‹¤"
        ]
        rooms_found = set()
        for keyword_pattern in room_keywords:
            # ë‹¨ì–´ ê²½ê³„(\\b)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ í–¥ìƒ
            matches = re.findall(r'\\b(' + keyword_pattern + r')\\b', text_content)
            for room in matches:
                # "ì¹¨ì‹¤1", "ì¹¨ì‹¤" ê³¼ ê°™ì€ ê²½ìš° "ì¹¨ì‹¤"ë¡œ ì •ê·œí™” (ì„ íƒì )
                room_normalized = re.sub(r'[0-9]+$', '', room)
                rooms_found.add(room_normalized)
        metadata["room_list"] = sorted(list(rooms_found))

        # ì¸µ ì •ë³´ (Level Information) - ì§€í•˜, ì§€ìƒ, ì˜¥íƒ‘ ë“±
        level_patterns = [
            r"([ ì§€í•˜]+[0-9]+ì¸µ|[0-9]+ì¸µ|ì˜¥íƒ‘ì¸µ|ì§€ë¶•ì¸µ|PH)", # ì§€í•˜1ì¸µ, 1ì¸µ, 15ì¸µ, ì˜¥íƒ‘ì¸µ, PH
            r"FL(?:\\s*\\.\\s*|\\s*)([+-]?[0-9,]+\\.?[0-9]*)",  # FL. +1,230, FL -500
            r"EL(?:\\s*\\.\\s*|\\s*)([+-]?[0-9,]+\\.?[0-9]*)",  # EL. +1,230
            r"LEVEL\\s*([0-9A-Za-z]+)" # LEVEL 1, LEVEL B1
        ]
        levels = set()
        for pattern in level_patterns:
            matches = re.findall(pattern, text_content, re.IGNORECASE)
            for match_item in matches:
                # match_itemì´ íŠœí”Œì¼ ìˆ˜ ìˆìŒ (ì—¬ëŸ¬ ê·¸ë£¹ ìº¡ì²˜ ì‹œ)
                level = match_item if isinstance(match_item, str) else match_item[0]
                levels.add(level.strip())
        metadata["level_info"] = sorted(list(levels))

        # ì£¼ìš” ì¹˜ìˆ˜ (Dimensions) - ì˜ˆ: 3,500 x 4,200 / W1200 x H2100
        # ì¢€ ë” ê±´ì¶• ë„ë©´ì— íŠ¹í™”ëœ ì¹˜ìˆ˜ íŒ¨í„´
        dimension_patterns = [
            r"\\b([0-9,]{3,})\\s*X\\s*([0-9,]{3,})\\b",  # 3,500 X 4,200 (ê³µë°± í—ˆìš©)
            r"\\bW([0-9,]+)\\s*X\\s*H([0-9,]+)\\b", # W1200 X H2100
            r"\\b[XY](?:=|:)?\\s*([0-9,.]+)\\b", # X=100.50, Y:2500
            # ì¼ë°˜ì ì¸ ìˆ«ì ì‹œí€€ìŠ¤ (ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆì–´ ì£¼ì˜)
            # r"\\b([0-9]{3,5})\\b" # 3ìë¦¬ ì´ìƒ 5ìë¦¬ ì´í•˜ ìˆ«ì (ë‹¨ë… ì¹˜ìˆ˜)
        ]
        dimensions_found = []
        for pattern in dimension_patterns:
            matches = re.findall(pattern, text_content)
            for match_item in matches:
                if isinstance(match_item, tuple) and len(match_item) == 2:
                    dimensions_found.append(f"{match_item[0].strip()}x{match_item[1].strip()}")
                elif isinstance(match_item, str):
                     dimensions_found.append(match_item.strip())
        metadata["dimensions"] = list(set(dimensions_found))[:15] # ì¤‘ë³µ ì œê±° ë° ê°œìˆ˜ ì œí•œ
        
        return metadata

    def analyze_project_relationships(self, drawings_metadata_list):
        """í”„ë¡œì íŠ¸ ë‚´ ë„ë©´ ê´€ê³„ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€ ë˜ëŠ” ê°œì„ )"""
        relationships = []
        if not drawings_metadata_list:
            return relationships

        # 1. ë„ë©´ ë²ˆí˜¸ ìˆœì„œì— ë”°ë¥¸ ì—°ê´€ì„± (ì˜ˆ: A-101, A-102ëŠ” ì‹œë¦¬ì¦ˆì¼ ê°€ëŠ¥ì„±)
        # ì •ë ¬ì„ ìœ„í•´ ë„ë©´ ë²ˆí˜¸ë¥¼ íŒŒì‹± ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜ ì‹œë„
        def sort_key_dwg_number(dwg):
            num_part = re.findall(r'\\d+', dwg.get("drawing_number", ""))
            if num_part:
                return int(num_part[-1]) # ë§ˆì§€ë§‰ ìˆ«ì ë¶€ë¶„ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            return float('inf') # ìˆ«ì ì—†ìœ¼ë©´ ë’¤ë¡œ

        sorted_drawings = sorted(drawings_metadata_list, key=lambda d: (
            re.sub(r'[^A-Z]', '', d.get("drawing_number","ZZZ")), # ì•ŒíŒŒë²³ ë¶€ë¶„
            sort_key_dwg_number(d) # ìˆ«ì ë¶€ë¶„
        ))

        for i in range(len(sorted_drawings) - 1):
            d1 = sorted_drawings[i]
            d2 = sorted_drawings[i+1]
            d1_num = d1.get("drawing_number", "N/A")
            d2_num = d2.get("drawing_number", "N/A")

            # ë„ë©´ ë²ˆí˜¸ ì•ë¶€ë¶„ì´ ìœ ì‚¬í•˜ê³  ë’·ë¶€ë¶„ ìˆ«ìë§Œ 1 ì°¨ì´ ë‚˜ëŠ” ê²½ìš°
            d1_match = re.match(r'(.*[^0-9])([0-9]+)$', d1_num)
            d2_match = re.match(r'(.*[^0-9])([0-9]+)$', d2_num)

            if d1_match and d2_match:
                if d1_match.group(1) == d2_match.group(1) and int(d2_match.group(2)) == int(d1_match.group(2)) + 1:
                    relationships.append({
                        "type": "sequential_drawings",
                        "drawings": [d1_num, d2_num],
                        "description": f"ì—°ì†ëœ ë„ë©´: {d1_num} -> {d2_num}"
                    })
        
        # 2. ë™ì¼ ë„ë©´ ìœ í˜• ê·¸ë£¹í•‘ (ê¸°ì¡´ ë¡œì§)
        type_groups = {}
        for drawing in drawings_metadata_list:
            drawing_type = drawing.get('drawing_type', 'unknown_type')
            if drawing_type == "ê·¼ê±° ë¶€ì¡±": drawing_type = "unknown_type"
            if drawing_type not in type_groups:
                type_groups[drawing_type] = []
            type_groups[drawing_type].append(drawing.get("drawing_number", "N/A"))
        
        for type_name, dwg_numbers in type_groups.items():
            if len(dwg_numbers) > 1:
                relationships.append({
                    "type": "same_type_collection",
                    "drawing_type": type_name,
                    "drawings": dwg_numbers,
                    "description": f"ë™ì¼ ìœ í˜• ë„ë©´ ê·¸ë£¹: {type_name} ({len(dwg_numbers)}ê°œ)"
                })

        # 3. ì°¸ì¡° ê´€ê³„ (ì˜ˆ: "SEE DWG A-DETAIL-001") - í…ìŠ¤íŠ¸ ë‚´ìš©ì—ì„œ íƒìƒ‰
        ref_pattern = r"(?:ì°¸ì¡°|SEE|REFER TO)\\s*(?:DWG\\.?|ë„ë©´)?\\s*([A-Z0-9\\-_./]+)"
        for drawing in drawings_metadata_list:
            text_snippet = drawing.get("raw_text_snippet", "")
            source_dwg_num = drawing.get("drawing_number", "N/A")
            found_refs = re.findall(ref_pattern, text_snippet, re.IGNORECASE)
            for ref_dwg_num in found_refs:
                # ìê¸° ìì‹ ì„ ì°¸ì¡°í•˜ëŠ” ê²½ìš°ëŠ” ì œì™¸
                if source_dwg_num != ref_dwg_num.strip():
                    relationships.append({
                        "type": "reference",
                        "source_drawing": source_dwg_num,
                        "referenced_drawing": ref_dwg_num.strip(),
                        "description": f"{source_dwg_num}ì´(ê°€) {ref_dwg_num.strip()}ì„(ë¥¼) ì°¸ì¡°"
                    })
        return relationships

    def generate_project_summary_info(self, project_name, project_path, drawings_metadata, relationships):
        """í”„ë¡œì íŠ¸ ì „ì²´ ìš”ì•½ ì •ë³´ ìƒì„±"""
        summary = {
            "project_name": project_name,
            "project_path": project_path,
            "total_drawings_processed": len(drawings_metadata),
            "drawing_types_summary": {}, # ë„ë©´ ìœ í˜•ë³„ ê°œìˆ˜
            "total_relationships_found": len(relationships),
            "key_drawing_numbers": [], # ì£¼ìš” ë„ë©´ ë²ˆí˜¸ (ì˜ˆ: ë°°ì¹˜ë„, ê¸°ì¤€ì¸µ í‰ë©´ë„)
            "overall_area_info": {}, # í”„ë¡œì íŠ¸ ì „ì²´ ë©´ì  ì •ë³´ (ê°€ëŠ¥í•˜ë‹¤ë©´)
            "extraction_timestamp": datetime.now().isoformat()
        }

        drawing_type_counts = {}
        for drawing in drawings_metadata:
            dtype = drawing.get("drawing_type", "unknown_type")
            if dtype == "ê·¼ê±° ë¶€ì¡±": dtype = "unknown_type"
            drawing_type_counts[dtype] = drawing_type_counts.get(dtype, 0) + 1
            
            # ì£¼ìš” ë„ë©´ ë²ˆí˜¸ í›„ë³´ (ì˜ˆì‹œ: "ë°°ì¹˜ë„", "ê¸°ì¤€ì¸µ", "í‰ë©´ë„" í‚¤ì›Œë“œ í¬í•¨)
            title = drawing.get("drawing_title", "").lower()
            if any(k in title for k in ["ë°°ì¹˜ë„", "site plan"]):
                summary["key_drawing_numbers"].append(f"{drawing.get('drawing_number', 'N/A')} (ë°°ì¹˜ë„)")
            elif any(k in title for k in ["ê¸°ì¤€ì¸µ", "typical floor"]) and "í‰ë©´ë„" in title:
                 summary["key_drawing_numbers"].append(f"{drawing.get('drawing_number', 'N/A')} (ê¸°ì¤€ì¸µ í‰ë©´ë„)")
        
        summary["drawing_types_summary"] = drawing_type_counts
        summary["key_drawing_numbers"] = list(set(summary["key_drawing_numbers"]))[:5] # ìƒìœ„ 5ê°œ

        # ì „ì²´ ë©´ì  ì •ë³´ ì§‘ê³„ (ì˜ˆì‹œ: ëŒ€ì§€ë©´ì , ì—°ë©´ì  ë“± í”„ë¡œì íŠ¸ ë ˆë²¨ ì •ë³´)
        # ë„ë©´ ë©”íƒ€ë°ì´í„°ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì•„ ì§‘ê³„ (ê°€ì¥ ì²˜ìŒ ë°œê²¬ëœ ê°’ ë˜ëŠ” ê°€ì¥ í° ê°’ ë“± ì •ì±… í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì²«ë²ˆì§¸ "site_area"ì™€ "total_floor_area"ë¥¼ ì‚¬ìš©
        for drawing in drawings_metadata:
            if "site_area" in drawing.get("area_info", {}) and "site_area" not in summary["overall_area_info"]:
                summary["overall_area_info"]["site_area"] = drawing["area_info"]["site_area"]
            if "total_floor_area" in drawing.get("area_info", {}) and "total_floor_area" not in summary["overall_area_info"]:
                summary["overall_area_info"]["total_floor_area"] = drawing["area_info"]["total_floor_area"]
            if "site_area" in summary["overall_area_info"] and "total_floor_area" in summary["overall_area_info"]:
                break # ë‘ ì •ë³´ ëª¨ë‘ ì°¾ìœ¼ë©´ ì¤‘ë‹¨

        return summary

    def process_project(self, project_name, project_data):
        """ê°œë³„ í”„ë¡œì íŠ¸ ì²˜ë¦¬í•˜ì—¬ ë©”íƒ€ë°ì´í„° ìƒì„±"""
        project_path_str = project_data.get("project_path", str(self.uploads_root_dir / project_name))
        project_specific_metadata = {
            "project_info": {}, # í”„ë¡œì íŠ¸ ìš”ì•½ ì •ë³´ê°€ ì—¬ê¸°ì— ë“¤ì–´ê°
            "drawings": [],
            "relationships": [],
        }
        
        print(f"\\nğŸ“„ Processing Project: {project_name} (Path: {project_path_str})")

        # 'pdf_files_text' í‚¤ë¥¼ ì‚¬ìš© (analyze_uploads_new.pyì˜ ê²°ê³¼ì— ë§ì¶¤)
        pdf_files_text_data = project_data.get("pdf_files_text", [])
        if not pdf_files_text_data:
            print(f"   âš ï¸ No PDF text data found for project {project_name}. Skipping.")
            # í”„ë¡œì íŠ¸ ìš”ì•½ë§Œì´ë¼ë„ ìƒì„±
            project_specific_metadata["project_info"] = self.generate_project_summary_info(
                project_name, project_path_str, [], []
            )
            return project_specific_metadata


        current_project_drawings_metadata = []
        for pdf_file_entry in pdf_files_text_data:
            file_name = pdf_file_entry.get("file")
            if not file_name:
                print("   âš ï¸ PDF file entry missing 'file' name. Skipping.")
                continue

            print(f"   ğŸ“„ Extracting metadata from: {file_name}")
            
            # 'pages_text' í‚¤ë¥¼ ì‚¬ìš© (analyze_uploads_new.pyì˜ ê²°ê³¼ì— ë§ì¶¤)
            pages_text_content = pdf_file_entry.get("pages_text", [])
            if 'error' in pdf_file_entry:
                 print(f"      âŒ Error reported for this file in analysis results: {pdf_file_entry['error']}. Skipping pages.")
                 continue

            for page_content_entry in pages_text_content:
                page_num = page_content_entry.get("page")
                text_content = page_content_entry.get("text_content", "")
                
                if page_num is None:
                    print("      âš ï¸ Page entry missing 'page' number. Skipping.")
                    continue

                if not text_content and "warning" in page_content_entry:
                    print(f"      âš ï¸ Page {page_num}: {page_content_entry['warning']}")
                
                # í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                # VLM ë¶„ì„ ê²°ê³¼ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ None ì „ë‹¬
                metadata = self.extract_drawing_metadata_from_text(text_content, file_name, page_num, project_path_str)
                current_project_drawings_metadata.append(metadata)
                
                # print(f"         âœ… Dwg No: {metadata['drawing_number']}, Title: {metadata['drawing_title'][:30]}...")

        project_specific_metadata["drawings"] = current_project_drawings_metadata
        
        # í”„ë¡œì íŠ¸ ë‚´ ë„ë©´ ê´€ê³„ ë¶„ì„
        print(f"   ğŸ” Analyzing relationships for project: {project_name}...")
        relationships = self.analyze_project_relationships(current_project_drawings_metadata)
        project_specific_metadata["relationships"] = relationships
        
        # í”„ë¡œì íŠ¸ ìš”ì•½ ìƒì„±
        project_summary = self.generate_project_summary_info(
            project_name,
            project_path_str,
            current_project_drawings_metadata,
            relationships
        )
        project_specific_metadata["project_info"] = project_summary
        
        return project_specific_metadata

    def process_all_projects_and_save(self, output_base_filename="project_metadata"):
        """ëª¨ë“  í”„ë¡œì íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³ , ê° í”„ë¡œì íŠ¸ë³„ë¡œ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì €ì¥"""
        analysis_results_data = self.load_analysis_results()
        if not analysis_results_data:
            print("âŒ No analysis results loaded. Cannot proceed.")
            return

        all_projects_output_files = []

        for project_name, project_data_from_analysis in analysis_results_data.items():
            project_metadata_content = self.process_project(project_name, project_data_from_analysis)
            
            if project_metadata_content:
                # ì €ì¥ ê²½ë¡œ: uploads_dir / project_name / project_metadata_project_name.json
                # ë˜ëŠ” ë³„ë„ì˜ metadata í´ë”ì— ì €ì¥í•  ìˆ˜ë„ ìˆìŒ
                # ì—¬ê¸°ì„œëŠ” ì›ë³¸ í”„ë¡œì íŠ¸ í´ë” ë‚´ì— ì €ì¥
                
                # project_data_from_analysis["project_path"] ê°€ ì‹¤ì œ í”„ë¡œì íŠ¸ í´ë”ì˜ ì ˆëŒ€ ê²½ë¡œ
                # output_dir = Path(project_data_from_analysis.get("project_path", self.uploads_root_dir / project_name))
                
                # ì¼ê´€ì„±ì„ ìœ„í•´ self.uploads_root_dir ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì¬êµ¬ì„±
                # _default_projectì˜ ê²½ìš° uploads_root_dir ë°”ë¡œ ì•„ë˜
                if project_name == "_default_project":
                    output_dir = self.uploads_root_dir
                else:
                    output_dir = self.uploads_root_dir / project_name
                
                output_dir.mkdir(parents=True, exist_ok=True) # ì €ì¥ í´ë” ìƒì„±
                
                # íŒŒì¼ëª…ì— í”„ë¡œì íŠ¸ ì´ë¦„ í¬í•¨ (ì¤‘ë³µ ë°©ì§€ ë° ì‹ë³„ ìš©ì´)
                # slugify project_name for filename
                safe_project_name = "".join(c if c.isalnum() else "_" for c in project_name)
                output_file_path = output_dir / f"{output_base_filename}_{safe_project_name}.json"

                try:
                    with open(output_file_path, 'w', encoding='utf-8') as f:
                        json.dump(project_metadata_content, f, indent=2, ensure_ascii=False)
                    print(f"   ğŸ’¾ Project metadata saved to: {output_file_path}")
                    all_projects_output_files.append(str(output_file_path))
                except Exception as e:
                    print(f"   âŒ Failed to save metadata for {project_name}: {e}")
            else:
                print(f"   âš ï¸ No metadata generated for project {project_name}.")
        
        if all_projects_output_files:
            print(f"\\nğŸ‰ All projects processed. Metadata files created: {len(all_projects_output_files)}")
            for f_path in all_projects_output_files:
                print(f"     - {f_path}")
        else:
            print("\\nâš ï¸ No metadata files were generated for any project.")
        return all_projects_output_files

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ—ï¸  Architectural Project Metadata Extractor (Text-Based)")
    print("=" * 60)
    
    # uploads_analysis_results.json íŒŒì¼ì˜ ìœ„ì¹˜ì™€ uploads í´ë”ì˜ ë£¨íŠ¸ë¥¼ ì •í™•íˆ ì§€ì •
    # ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ VLM í´ë”ì— ìˆë‹¤ê³  ê°€ì •
    base_dir = Path(__file__).resolve().parent 
    analysis_json_file = base_dir / "uploads_analysis_results.json"
    uploads_folder = base_dir / "uploads"

    if not analysis_json_file.exists():
        print(f"âŒ Critical Error: Analysis results file not found at {analysis_json_file}")
        print("   Please run 'analyze_uploads_new.py' first to generate this file.")
        return
        
    extractor = ArchitecturalMetadataExtractor(
        analysis_file=str(analysis_json_file),
        uploads_root_dir=str(uploads_folder)
    )
    
    # ëª¨ë“  í”„ë¡œì íŠ¸ ì²˜ë¦¬ ë° ì €ì¥
    extractor.process_all_projects_and_save()

    print("\\nğŸ’¡ Next steps:")
    print("   - Review the generated project_metadata_*.json files in each project's subfolder within 'uploads'.")
    print("   - Use these JSON files as input for 'infer_relationships.py' and 'build_rag_db.py'.")

if __name__ == "__main__":
    main()
