#!/usr/bin/env python3
"""
ë©”íƒ€ë°ì´í„° ë²¡í„° DB ì„ë² ë”© ì‹œìŠ¤í…œ
jinaai/jina-embeddings-v3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê±´ì¶• ë„ë©´ ë©”íƒ€ë°ì´í„°ë¥¼ ë²¡í„°í™”
"""

import json
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime
import uuid

# ChromaDB ì„í¬íŠ¸
try:
    import chromadb
    from chromadb.config import Settings
    HAS_CHROMADB = True
except ImportError:
    print("ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install chromadbë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    HAS_CHROMADB = False

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.append(str(current_dir))

try:
    from embedding_config import get_jina_embeddings, EmbeddingConfig
    from env_config import get_env_str, get_env_int, get_env_float
except ImportError as e:
    print(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ ëª¨ë“ˆì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("pip install transformers torch einops chromadb")

logger = logging.getLogger(__name__)

class MetadataVectorDB:
    """ë©”íƒ€ë°ì´í„° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì"""
    
    def __init__(self, db_path: str = None, collection_name: str = None):
        """
        Args:
            db_path: ë²¡í„° DB ì €ì¥ ê²½ë¡œ
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        """
        self.db_path = db_path or get_env_str("VECTOR_DB_PATH", "./chroma_db")
        self.collection_name = collection_name or get_env_str("VECTOR_COLLECTION_NAME", "architectural_metadata")
        self.top_k = get_env_int("VECTOR_SEARCH_TOP_K", 10)
        self.similarity_threshold = get_env_float("VECTOR_SIMILARITY_THRESHOLD", 0.7)
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embeddings = None
        self.client = None
        self.collection = None
        
        self._initialize_db()
        self._initialize_embeddings()
    
    def _initialize_db(self):
        """ChromaDB ì´ˆê¸°í™”"""
        if not HAS_CHROMADB:
            raise ImportError("ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            self.client = chromadb.PersistentClient(
                path=self.db_path,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            self.collection = self.client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "ê±´ì¶• ë„ë©´ ë©”íƒ€ë°ì´í„° ë²¡í„° ì €ì¥ì†Œ"}
            )
            
            logger.info(f"âœ… ChromaDB ì´ˆê¸°í™” ì™„ë£Œ - ì»¬ë ‰ì…˜: {self.collection_name}")
            
        except Exception as e:
            logger.error(f"ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            self.embeddings = get_jina_embeddings()
            logger.info("âœ… Jina ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def load_metadata_files(self, metadata_dir: str) -> List[Dict[str, Any]]:
        """ë©”íƒ€ë°ì´í„° JSON íŒŒì¼ë“¤ ë¡œë“œ"""
        metadata_path = Path(metadata_dir)
        
        if not metadata_path.exists():
            raise FileNotFoundError(f"ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_dir}")
        
        metadata_list = []
        
        # ë‹¤ì–‘í•œ ë©”íƒ€ë°ì´í„° íŒŒì¼ íŒ¨í„´ ì§€ì›
        patterns = [
            "*_metadata.json",
            "*_metadata_*.json",  # backup íŒŒì¼ ë“±
            "metadata_*.json",
            "*.json"  # ì¼ë°˜ JSON íŒŒì¼ë„ ì‹œë„
        ]
        
        json_files = []
        for pattern in patterns:
            matches = list(metadata_path.glob(pattern))
            for match in matches:
                if match not in json_files:  # ì¤‘ë³µ ì œê±°
                    json_files.append(match)
        
        logger.info(f"ğŸ“ ë©”íƒ€ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘: {len(json_files)}ê°œ íŒŒì¼")
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                # ìœ íš¨í•œ ë©”íƒ€ë°ì´í„°ì¸ì§€ í™•ì¸ (ê¸°ë³¸ í•„ë“œ ì¡´ì¬ ì—¬ë¶€)
                if not isinstance(metadata, dict):
                    logger.warning(f"âš ï¸  ìœ íš¨í•˜ì§€ ì•Šì€ ë©”íƒ€ë°ì´í„° í˜•ì‹: {json_file.name}")
                    continue
                
                # íŒŒì¼ ì •ë³´ ì¶”ê°€
                metadata['_file_info'] = {
                    'filename': json_file.name,
                    'filepath': str(json_file),
                    'file_id': json_file.stem.replace('_metadata', '').replace('_backup', ''),
                    'load_timestamp': datetime.now().isoformat()
                }
                
                metadata_list.append(metadata)
                logger.debug(f"âœ… ë¡œë“œë¨: {json_file.name}")
                
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜ {json_file.name}: {e}")
            except Exception as e:
                logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {json_file.name}: {e}")
        
        logger.info(f"âœ… {len(metadata_list)}ê°œ ë©”íƒ€ë°ì´í„° íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        return metadata_list
    
    def create_embeddings_text(self, metadata: Dict[str, Any]) -> str:
        """ë©”íƒ€ë°ì´í„°ë¥¼ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        text_parts = []
        
        # í”„ë¡œì íŠ¸ ì •ë³´
        project_info = metadata.get('project_info', {})
        if project_info:
            text_parts.append(f"í”„ë¡œì íŠ¸: {project_info.get('project_name', '')}")
            text_parts.append(f"ë„ë©´ìœ í˜•: {project_info.get('drawing_type', '')}")
            text_parts.append(f"ë¶„ì•¼: {project_info.get('discipline', '')}")
            text_parts.append(f"ëª©ì : {project_info.get('drawing_purpose', '')}")
        
        # ë„ë©´ ë©”íƒ€ë°ì´í„°
        drawing_metadata = metadata.get('drawing_metadata', {})
        if drawing_metadata:
            text_parts.append(f"ì œëª©: {drawing_metadata.get('title', '')}")
            text_parts.append(f"ì„¤ëª…: {drawing_metadata.get('description', '')}")
            
            keywords = drawing_metadata.get('keywords', [])
            if keywords:
                text_parts.append(f"í‚¤ì›Œë“œ: {', '.join(keywords)}")
                
            text_parts.append(f"ê±´ë¬¼ìœ í˜•: {drawing_metadata.get('building_type', '')}")
            text_parts.append(f"ë³µì¡ë„: {drawing_metadata.get('complexity_level', '')}")
        
        # ê±´ì¶•ì  íŠ¹ì§•
        arch_features = metadata.get('architectural_features', {})
        if arch_features:
            spatial_org = arch_features.get('spatial_organization', {})
            if spatial_org:
                text_parts.append(f"ê³µê°„êµ¬ì„±: {spatial_org.get('description', '')}")
                
                spaces = spatial_org.get('identified_spaces', [])
                if spaces:
                    text_parts.append(f"ì‹ë³„ê³µê°„: {', '.join(spaces)}")
            
            design_elements = arch_features.get('design_elements', {})
            if design_elements:
                text_parts.append(f"ì„¤ê³„ìš”ì†Œ: {design_elements.get('description', '')}")
        
        # ê¸°ìˆ ì  ì‚¬ì–‘
        tech_specs = metadata.get('technical_specifications', {})
        if tech_specs:
            text_parts.append(f"íŒŒì¼í˜•ì‹: {tech_specs.get('file_format', '')}")
            text_parts.append(f"ë‹¨ìœ„: {tech_specs.get('units', '')}")
            text_parts.append(f"ì¶•ì²™: {tech_specs.get('scale', '')}")
        
        # íŒŒì¼ ì •ë³´
        file_info = metadata.get('_file_info', {})
        if file_info:
            text_parts.append(f"íŒŒì¼ID: {file_info.get('file_id', '')}")
        
        return " | ".join([part for part in text_parts if part.strip()])
    
    def embed_metadata(self, metadata_list: List[Dict[str, Any]]) -> bool:
        """ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„° DBì— ì„ë² ë”©"""
        if not metadata_list:
            logger.warning("ì„ë² ë”©í•  ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            logger.info(f"ğŸ”„ {len(metadata_list)}ê°œ ë©”íƒ€ë°ì´í„° ì„ë² ë”© ì‹œì‘")
            
            # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±
            texts = []
            ids = []
            metadatas = []
            
            for metadata in metadata_list:
                # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±
                embedding_text = self.create_embeddings_text(metadata)
                texts.append(embedding_text)
                
                # ê³ ìœ  ID ìƒì„±
                file_info = metadata.get('_file_info', {})
                doc_id = file_info.get('file_id', str(uuid.uuid4()))
                ids.append(doc_id)
                
                # ë©”íƒ€ë°ì´í„° (ê²€ìƒ‰ìš©)
                search_metadata = {
                    'project_name': metadata.get('project_info', {}).get('project_name', ''),
                    'drawing_type': metadata.get('project_info', {}).get('drawing_type', ''),
                    'title': metadata.get('drawing_metadata', {}).get('title', ''),
                    'discipline': metadata.get('project_info', {}).get('discipline', ''),
                    'filename': file_info.get('filename', ''),
                    'file_id': file_info.get('file_id', ''),
                    'embedding_timestamp': datetime.now().isoformat()
                }
                metadatas.append(search_metadata)
            
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            logger.info("ğŸ“Š í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘...")
            embeddings = self.embeddings.encode(texts, task="retrieval.passage")
            
            # ChromaDBì— ì €ì¥
            logger.info("ğŸ’¾ ChromaDBì— ì €ì¥ ì¤‘...")
            self.collection.add(
                ids=ids,
                embeddings=embeddings,
                metadatas=metadatas,
                documents=texts
            )
            
            logger.info(f"âœ… {len(metadata_list)}ê°œ ë©”íƒ€ë°ì´í„° ì„ë² ë”© ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° ì„ë² ë”© ì‹¤íŒ¨: {e}")
            return False
    
    def embed_and_store_metadata(self, metadata_list: List[Dict[str, Any]]) -> Dict[str, int]:
        """ë©”íƒ€ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ê³  ë²¡í„° DBì— ì €ì¥ (ê²°ê³¼ ë°˜í™˜)"""
        results = {
            'success_count': 0,
            'error_count': 0,
            'total_count': len(metadata_list)
        }
        
        if not metadata_list:
            logger.warning("ì„ë² ë”©í•  ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return results
        
        try:
            success = self.embed_metadata(metadata_list)
            if success:
                results['success_count'] = len(metadata_list)
            else:
                results['error_count'] = len(metadata_list)
        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° ì„ë² ë”© ë° ì €ì¥ ì‹¤íŒ¨: {e}")
            results['error_count'] = len(metadata_list)
        
        return results
    
    def search(self, query: str, top_k: int = None) -> List[Dict[str, Any]]:
        """ë²¡í„° ê²€ìƒ‰"""
        top_k = top_k or self.top_k
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self.embeddings.encode([query], task="retrieval.query")[0]
            
            # ë²¡í„° ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=['metadatas', 'documents', 'distances']
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            search_results = []
            if results['ids'] and results['ids'][0]:
                for i, doc_id in enumerate(results['ids'][0]):
                    distance = results['distances'][0][i]
                    
                    # ChromaDBëŠ” ê¸°ë³¸ì ìœ¼ë¡œ squared L2 distanceë¥¼ ì‚¬ìš©
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°: similarity = 1 - (distance / 2)
                    # ë˜ëŠ” ë‹¨ìˆœíˆ ê±°ë¦¬ì˜ ì—­ìˆ˜ ì‚¬ìš©
                    if distance > 0:
                        # ê±°ë¦¬ê°€ í´ìˆ˜ë¡ ìœ ì‚¬ë„ëŠ” ë‚®ì•„ì§
                        score = max(0, 1.0 / (1.0 + distance))
                    else:
                        score = 1.0
                    
                    result = {
                        'id': doc_id,
                        'score': score,
                        'distance': distance,  # ë””ë²„ê¹…ìš© ì¶”ê°€
                        'metadata': results['metadatas'][0][i],
                        'content': results['documents'][0][i]
                    }
                    
                    # ì„ê³„ê°’ í•„í„°ë§ (ì„ê³„ê°’ì„ ë‚®ì¶°ì„œ ì ìš©)
                    if result['score'] >= max(0.1, self.similarity_threshold * 0.5):  # ì„ê³„ê°’ì˜ ì ˆë°˜ìœ¼ë¡œ ì™„í™”
                        search_results.append(result)
            
            logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼ (ì„ê³„ê°’: {self.similarity_threshold})")
            return search_results
            
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def search_similar_metadata(self, query: str, top_k: int = None) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ (ë³„ì¹­ ë©”ì„œë“œ)"""
        results = self.search(query, top_k)
        
        # ê²°ê³¼ í˜•ì‹ì„ ë§ì¶¤
        formatted_results = []
        for result in results:
            formatted_result = {
                'similarity': result['score'],
                'metadata': result['metadata'],
                'content': result['content'],
                'id': result['id']
            }
            formatted_results.append(formatted_result)
        
        return formatted_results
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´ (ì—…ë°ì´íŠ¸)"""
        try:
            count = self.collection.count()
            return {
                'collection_name': self.collection_name,
                'total_vectors': count,  # 'document_count' ëŒ€ì‹  'total_vectors' ì‚¬ìš©
                'db_path': self.db_path,
                'embedding_model': self.embeddings.config.model_name if self.embeddings else 'Unknown'
            }
        except Exception as e:
            logger.error(f"í†µê³„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'collection_name': self.collection_name,
                'total_vectors': 0,
                'db_path': self.db_path,
                'embedding_model': 'Unknown'
            }
    
    def clear_collection(self):
        """ì»¬ë ‰ì…˜ ë°ì´í„° ì´ˆê¸°í™”"""
        try:
            # ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
            self.client.delete_collection(self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "ê±´ì¶• ë„ë©´ ë©”íƒ€ë°ì´í„° ë²¡í„° ì €ì¥ì†Œ"}
            )
            logger.info(f"âœ… ì»¬ë ‰ì…˜ '{self.collection_name}' ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

def create_metadata_vector_db(metadata_dir: str, force_recreate: bool = False) -> MetadataVectorDB:
    """ë©”íƒ€ë°ì´í„° ë²¡í„° DB ìƒì„±"""
    try:
        # ë²¡í„° DB ì´ˆê¸°í™”
        vector_db = MetadataVectorDB()
        
        # ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™” (ì˜µì…˜)
        if force_recreate:
            logger.info("ğŸ—‘ï¸  ê¸°ì¡´ ë²¡í„° DB ë°ì´í„° ì´ˆê¸°í™”")
            vector_db.clear_collection()
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        metadata_list = vector_db.load_metadata_files(metadata_dir)
        
        if not metadata_list:
            logger.warning("ì„ë² ë”©í•  ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return vector_db
        
        # ì„ë² ë”© ë° ì €ì¥
        success = vector_db.embed_metadata(metadata_list)
        
        if success:
            stats = vector_db.get_collection_stats()
            logger.info(f"ğŸ“Š ë²¡í„° DB ìƒì„± ì™„ë£Œ: {stats}")
        
        return vector_db
        
    except Exception as e:
        logger.error(f"ë©”íƒ€ë°ì´í„° ë²¡í„° DB ìƒì„± ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬
    metadata_dir = "uploads/01_í–‰ë³µë„ì‹œ 6-3ìƒí™œê¶ŒM3BL ì‹¤ì‹œì„¤ê³„ë„ë©´2ì°¨ ê±´ì¶•ë„ë©´/metadata"
    
    try:
        # ë²¡í„° DB ìƒì„±
        vector_db = create_metadata_vector_db(metadata_dir, force_recreate=True)
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        test_queries = [
            "ì§€í•˜ì£¼ì°¨ì¥ ë„ë©´",
            "ì£¼ë™ ì…ë©´ë„",
            "ë©´ì  ê³„ì‚°",
            "ì°½í˜¸ ì„¤ê³„"
        ]
        
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰:")
        for query in test_queries:
            results = vector_db.search(query, top_k=3)
            print(f"\nê²€ìƒ‰ì–´: '{query}'")
            
            if results:
                for i, result in enumerate(results, 1):
                    print(f"  {i}. {result['metadata']['title']} (ìœ ì‚¬ë„: {result['score']:.3f})")
            else:
                print("  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
