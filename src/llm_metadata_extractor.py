#!/usr/bin/env python3
"""
LLM ê¸°ë°˜ ê±´ì¶• ë„ë©´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸°
PDF í…ìŠ¤íŠ¸ì—ì„œ ê±´ì¶• ë„ë©´ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
.env íŒŒì¼ì˜ ì„¤ì •ì„ ì‚¬ìš©í•˜ê³ , Ollamaì™€ LangChainì„ ì—°ë™í•©ë‹ˆë‹¤.
"""

import json
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
import re

try:
    from langchain_ollama import ChatOllama
    HAS_OLLAMA = True
except ImportError:
    print("langchain-ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install langchain-ollamaë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    ChatOllama = None
    HAS_OLLAMA = False

# MultiLLMWrapper import
try:
    from .multi_llm_wrapper import MultiLLMWrapper
except ImportError:
    try:
        from multi_llm_wrapper import MultiLLMWrapper
    except ImportError:
        MultiLLMWrapper = None

# ì ˆëŒ€ import ë˜ëŠ” sys.path ê¸°ë°˜ import
try:
    from prompt_manager import get_prompt_manager
except ImportError:
    import sys
    from pathlib import Path
    current_dir = str(Path(__file__).parent)
    if current_dir not in sys.path:
        sys.path.append(current_dir)
    from prompt_manager import get_prompt_manager

# í™˜ê²½ ì„¤ì • import
try:
    from env_config import EnvironmentConfig, get_env_str
except ImportError:
    import sys
    from pathlib import Path
    current_dir = str(Path(__file__).parent)
    if current_dir not in sys.path:
        sys.path.append(current_dir)
    from env_config import EnvironmentConfig, get_env_str

# LangSmith ì¶”ì  import
try:
    from langsmith_integration import trace_llm_call, LangSmithTracker
except ImportError:
    print("âš ï¸  LangSmith ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
    def trace_llm_call(name): 
        return lambda x: x
    class LangSmithTracker: 
        def __init__(self):
            pass

logger = logging.getLogger(__name__)

class LLMMetadataExtractor:
    """LLMì„ ì‚¬ìš©í•œ ê±´ì¶• ë„ë©´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° (Ollama ì—°ë™)"""
    
    def __init__(self, llm_wrapper=None, model_name: str = None, base_url: str = None):
        """
        Args:
            llm_wrapper: MultiLLMWrapper ì¸ìŠ¤í„´ìŠ¤ (ê¶Œì¥)
            model_name: ì‚¬ìš©í•  ëª¨ë¸ëª… (Noneì´ë©´ .envì—ì„œ ë¡œë“œ) - í˜¸í™˜ì„±ìš©
            base_url: ì„œë²„ ì£¼ì†Œ (Ollamaì˜ ê²½ìš°) - í˜¸í™˜ì„±ìš©
        """
        self.env_config = EnvironmentConfig()
        self.prompt_manager = get_prompt_manager()  # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì¶”ê°€
        
        # Multi-LLM Wrapper ì§ì ‘ ì‚¬ìš©
        if llm_wrapper is not None and hasattr(llm_wrapper, 'invoke'):
            self.llm = llm_wrapper
        else:
            # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ fallback
            from multi_llm_wrapper import get_llm
            self.llm = get_llm(
                model_name=model_name,
                base_url=base_url,
                temperature=0.1,  # ë©”íƒ€ë°ì´í„° ì¶”ì¶œì€ ì¼ê´€ì„±ì´ ì¤‘ìš”
                num_predict=1024,  # ë©”íƒ€ë°ì´í„° ì¶”ì¶œìš©ìœ¼ë¡œ ì¶©ë¶„í•œ í† í°
            timeout=60,  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        )
        
        logger.info(f"LLM ì´ˆê¸°í™” ì™„ë£Œ - ì œê³µì: {self.llm.get_provider()}, ëª¨ë¸: {self.llm.get_model_name()}")
        
    def _initialize_llm(self):
        """ë ˆê±°ì‹œ ë©”ì„œë“œ - Multi-LLM Wrapperë¡œ ëŒ€ì²´ë¨"""
        pass

    def _create_metadata_extraction_prompt(self, text_content: str, file_name: str, page_number: int) -> str:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± - ì¤‘ì•™ ê´€ë¦¬ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©"""
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (4000ì)
        truncated_text = text_content[:4000]
        if len(text_content) > 4000:
            truncated_text += "..."
        
        return self.prompt_manager.format_prompt(
            "pdf_metadata_extraction",
            file_name=file_name,
            page_number=page_number,
            text_content=truncated_text,
            html_content="",
            tables_data="",
            has_images=False
        )

    def _create_enhanced_metadata_extraction_prompt(self, text_content: str, file_name: str, 
                                                  page_number: int, html_content: str = "", 
                                                  tables_data: List[Dict] = None, 
                                                  has_images: bool = False) -> str:
        """í–¥ìƒëœ ë©”íƒ€ë°ì´í„° ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± - HTMLê³¼ í‘œ ë°ì´í„° í¬í•¨"""
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (3000ì)
        truncated_text = text_content[:3000]
        if len(text_content) > 3000:
            truncated_text += "..."
        
        # HTML ë‚´ìš© ê¸¸ì´ ì œí•œ (1000ì)
        truncated_html = html_content[:1000] if html_content else ""
        if html_content and len(html_content) > 1000:
            truncated_html += "..."
        
        # í‘œ ë°ì´í„° ì •ë¦¬ ë° ì œí•œ
        tables_str = ""
        if tables_data:
            tables_list = []
            for i, table in enumerate(tables_data[:5]):  # ìµœëŒ€ 5ê°œ í‘œë§Œ
                table_content = table.get('content', '')
                if len(table_content) > 500:  # ê° í‘œ ë‚´ìš© 500ì ì œí•œ
                    table_content = table_content[:500] + "..."
                bbox = table.get('bbox', [])
                tables_list.append(f"í‘œ {i+1}: {table_content} (ìœ„ì¹˜: {bbox})")
            tables_str = "\n".join(tables_list)
        
        return self.prompt_manager.format_prompt(
            "pdf_metadata_extraction",
            file_name=file_name,
            page_number=page_number,
            text_content=truncated_text,
            html_content=truncated_html if truncated_html else "HTML ë°ì´í„° ì—†ìŒ",
            tables_data=tables_str if tables_str else "í‘œ ë°ì´í„° ì—†ìŒ",
            has_images=has_images
        )

    @trace_llm_call(name="Extract Metadata from Text")
    def extract_metadata_from_text(self, text_content: str, file_name: str, page_number: int, 
                                 html_content: str = "", tables_data: List[Dict] = None, 
                                 has_images: bool = False) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸, HTML, í‘œ ë°ì´í„°ì—ì„œ LLMì„ ì‚¬ìš©í•˜ì—¬ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        
        if not self.llm:
            return self._fallback_regex_extraction(text_content, file_name, page_number)
        
        try:
            prompt = self._create_enhanced_metadata_extraction_prompt(
                text_content, file_name, page_number, html_content, tables_data, has_images
            )
            
            # Multi-LLM Wrapper í˜¸ì¶œ
            response = self.llm.invoke(prompt)
            
            # JSON ì‘ë‹µ íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            try:
                # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
                cleaned_response = self._clean_json_response(response)
                metadata = json.loads(cleaned_response)
                
                # ê¸°ë³¸ ì •ë³´ ì¶”ê°€
                metadata["file_name"] = file_name
                metadata["page_number"] = page_number
                metadata["raw_text_snippet"] = text_content[:500]  # ì²˜ìŒ 500ì ì €ì¥
                metadata["processing_info"] = {
                    "has_html": bool(html_content),
                    "has_tables": bool(tables_data),
                    "table_count": len(tables_data) if tables_data else 0,
                    "has_images": has_images
                }
                
                # ìœ íš¨ì„± ê²€ì‚¬ ë° ê¸°ë³¸ê°’ ì„¤ì •
                metadata = self._validate_and_clean_metadata(metadata)
                
                return metadata
                
            except json.JSONDecodeError:
                logger.warning(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹± ì‹¤íŒ¨: {response[:200]}...")
                return self._fallback_regex_extraction(text_content, file_name, page_number)
                
        except Exception as e:
            logger.error(f"LLM ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._fallback_regex_extraction(text_content, file_name, page_number)

    def extract_metadata_from_json_self_query(self, raw_json: Dict[str, Any], file_name: str, page_number: int) -> Dict[str, Any]:
        """
        ì´ë¯¸ JSONìœ¼ë¡œ ì¶”ì¶œëœ ì›ì‹œ ë°ì´í„°ë¥¼ LLMì„ ì‚¬ìš©í•´ Self-Query í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            raw_json: JSON í˜•ì‹ì˜ ì›ì‹œ ë©”íƒ€ë°ì´í„° ë°ì´í„°
            file_name: ì›ë³¸ íŒŒì¼ ì´ë¦„
            page_number: ì²˜ë¦¬ëœ í˜ì´ì§€ ë²ˆí˜¸
        Returns:
            íŒŒì‹±ëœ ë©”íƒ€ë°ì´í„° ì‚¬ì „
        """
        # raw_jsonì„ ë¬¸ìì—´ë¡œ ì§ë ¬í™”
        json_str = json.dumps(raw_json, ensure_ascii=False)
        # Self-Query íŒŒì‹± í”„ë¡¬í”„íŠ¸ ìƒì„± (prompt_managerì— 'self_query_parsing' í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ìˆë‹¤ê³  ê°€ì •)
        prompt = self.prompt_manager.format_prompt(
            "self_query_parsing",
            json_data=json_str,
            file_name=file_name,
            page_number=page_number
        )
        try:
            # LLM í˜¸ì¶œ
            response = self.llm.invoke(prompt)
            # JSONë§Œ ë‚¨ê¸°ë„ë¡ ì •ë¦¬
            cleaned = self._clean_json_response(response)
            parsed = json.loads(cleaned)
            # ê¸°ë³¸ í•„ë“œ ì¶”ê°€
            parsed["file_name"] = file_name
            parsed["page_number"] = page_number
            # ìœ íš¨ì„± ê²€ì‚¬ ë° ì •ë¦¬
            return self._validate_and_clean_metadata(parsed)
        except Exception as e:
            logger.warning(f"Self-Query í˜•ì‹ íŒŒì‹± ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì¶œ ì‚¬ìš©
            return self._fallback_regex_extraction(json_str, file_name, page_number)

    def _validate_and_clean_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ë° ì •ë¦¬"""
        
        # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’ ì„¤ì •
        defaults = {
            "drawing_number": "ê·¼ê±° ë¶€ì¡±",
            "drawing_title": "ì •ë³´ ì—†ìŒ",
            "drawing_type": "ê¸°íƒ€",
            "scale": "ì •ë³´ ì—†ìŒ",
            "level_info": [],
            "room_list": [],
            "area_info": {},
            "materials": [],
            "dimensions": [],
            "symbols_annotations": []
        }
        
        for key, default_value in defaults.items():
            if key not in metadata or metadata[key] is None:
                metadata[key] = default_value
        
        # ë¦¬ìŠ¤íŠ¸ íƒ€ì… ê²€ì¦
        list_fields = ["level_info", "room_list", "materials", "dimensions", "symbols_annotations"]
        for field in list_fields:
            if not isinstance(metadata[field], list):
                metadata[field] = []
        
        # ë¬¸ìì—´ íƒ€ì… ê²€ì¦
        string_fields = ["drawing_number", "drawing_title", "drawing_type", "scale"]
        for field in string_fields:
            if not isinstance(metadata[field], str):
                metadata[field] = str(metadata[field]) if metadata[field] else defaults[field]
        
        return metadata

    def _fallback_regex_extraction(self, text_content: str, file_name: str, page_number: int) -> Dict[str, Any]:
        """LLM ì‹¤íŒ¨ ì‹œ ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ í´ë°± ì¶”ì¶œ"""
        
        metadata = {
            "file_name": file_name,
            "page_number": page_number,
            "drawing_number": "ê·¼ê±° ë¶€ì¡±",
            "drawing_title": "ì •ë³´ ì—†ìŒ",
            "drawing_type": "ê¸°íƒ€",
            "scale": "ì •ë³´ ì—†ìŒ",
            "level_info": [],
            "room_list": [],
            "area_info": {},
            "materials": [],
            "dimensions": [],
            "symbols_annotations": [],
            "raw_text_snippet": text_content[:500]
        }
        
        # ê°„ë‹¨í•œ ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ ì¶”ì¶œ
        
        # ë„ë©´ë²ˆí˜¸ ì¶”ì¶œ
        drawing_number_patterns = [
            r"[A-Z]+\d*[-_]\d+",  # A01-001, B1_002 ë“±
            r"ë„ë©´\s*ë²ˆí˜¸\s*[:\s]*([A-Z0-9\-_]+)",
            r"DWG\s*NO\s*[:\s]*([A-Z0-9\-_]+)"
        ]
        
        for pattern in drawing_number_patterns:
            match = re.search(pattern, text_content, re.IGNORECASE)
            if match:
                if len(pattern.split('(')) > 1:  # ê·¸ë£¹ì´ ìˆëŠ” íŒ¨í„´
                    metadata["drawing_number"] = match.group(1).strip()
                else:
                    metadata["drawing_number"] = match.group(0).strip()
                break
        
        # ì¶•ì²™ ì¶”ì¶œ
        scale_patterns = [
            r"SCALE\s*[:\s]*([0-9/:]+)",
            r"ì¶•ì²™\s*[:\s]*([0-9/:]+)",
            r"S\s*=\s*([0-9/:]+)"
        ]
        
        for pattern in scale_patterns:
            match = re.search(pattern, text_content, re.IGNORECASE)
            if match:
                metadata["scale"] = match.group(1).strip()
                break
        
        return metadata

    def _clean_json_response(self, response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬"""
        if not response:
            return ""
            
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```json" in response:
            # ```jsonê³¼ ``` ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ
            start = response.find("```json") + 7
            end = response.find("```", start)
            if end != -1:
                response = response[start:end].strip()
        elif "```" in response:
            # ì¼ë°˜ ì½”ë“œ ë¸”ë¡ ì œê±°
            start = response.find("```") + 3
            end = response.find("```", start)
            if end != -1:
                response = response[start:end].strip()
        
        # JSON ì‹œì‘ê³¼ ë ì°¾ê¸°
        start_brace = response.find("{")
        end_brace = response.rfind("}")
        
        if start_brace != -1 and end_brace != -1 and end_brace > start_brace:
            response = response[start_brace:end_brace + 1]
        
        return response.strip()

    def batch_extract_metadata(self, text_data_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì—ì„œ ë°°ì¹˜ë¡œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        
        results = []
        total = len(text_data_list)
        
        print(f"ğŸ¤– LLMìœ¼ë¡œ {total}ê°œ ë„ë©´ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...")
        
        for i, text_data in enumerate(text_data_list):
            text_content = text_data.get("text_content", "")
            file_name = text_data.get("file_name", "unknown")
            page_number = text_data.get("page_number", 0)
            
            metadata = self.extract_metadata_from_text(text_content, file_name, page_number)
            results.append(metadata)
            
            if (i + 1) % 50 == 0:
                print(f"   ì§„í–‰ë¥ : {i + 1}/{total} ({(i + 1)/total*100:.1f}%)")
        
        print(f"âœ… LLM ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(results)}ê°œ ì²˜ë¦¬")
        return results

def test_llm_metadata_extraction():
    """LLM ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    
    # í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸
    test_text = """
    ë„ë©´ë²ˆí˜¸: A01-001
    ë„ë©´ì œëª©: 1ì¸µ í‰ë©´ë„
    ì¶•ì²™: 1/100
    
    ê±°ì‹¤ 45.2ã¡
    ì£¼ë°© 12.5ã¡ 
    ì¹¨ì‹¤1 15.8ã¡
    ìš•ì‹¤ 4.2ã¡
    
    ì „ìš©ë©´ì : 85.2ã¡
    ê³µê¸‰ë©´ì : 102.5ã¡
    """
    
    try:
        extractor = LLMMetadataExtractor()
        result = extractor.extract_metadata_from_text(test_text, "test.pdf", 1)
        
        print("ğŸ§ª LLM ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_llm_metadata_extraction()
