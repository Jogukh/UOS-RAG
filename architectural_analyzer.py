#!/usr/bin/env python3
"""
ğŸ—ï¸ ê±´ì¶• ë„ë©´ ë¶„ì„ ì‹œìŠ¤í…œ (í†µí•© ë²„ì „)
PDF ê±´ì¶• ë„ë©´ì„ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python architectural_analyzer.py [PDFíŒŒì¼ê²½ë¡œ] [ì˜µì…˜]
    
ì˜µì…˜:
    --output-dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: analysis_results)
    --format: ì¶œë ¥ í˜•ì‹ (json, html, both) (ê¸°ë³¸ê°’: both)
    --model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: .envì—ì„œ ì½ìŒ)
    --backend: ë°±ì—”ë“œ (vllm, transformers) (ê¸°ë³¸ê°’: transformers)
    --verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥
"""

import os
import sys
import json
import argparse
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
import shutil

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent / "src"))

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
try:
    from PIL import Image
    import fitz  # PyMuPDF
    from dotenv import load_dotenv
    
    # í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤
    from env_config import get_env_config
    from qwen_vlm_analyzer_fixed import QwenVLMAnalyzer
    from vllm_config import VLLMConfig
    
    print("âœ… ëª¨ë“  í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("pip install -r requirements.txt ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
def setup_logging(verbose: bool = False):
    """ë¡œê¹… ì„¤ì •"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('architectural_analysis.log')
        ]
    )
    return logging.getLogger(__name__)

# PDF ì²˜ë¦¬ í´ë˜ìŠ¤
class PDFProcessor:
    """PDF ì²˜ë¦¬ ë° ì´ë¯¸ì§€ ë³€í™˜"""
    
    def __init__(self, temp_dir: str = "temp_analysis"):
        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(exist_ok=True)
        
    def convert_pdf_to_images(self, pdf_path: str, max_pages: int = 10) -> List[tuple]:
        """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ìµœì í™”ëœ ë²„ì „)"""
        pdf_path = Path(pdf_path)
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
            
        print(f"ğŸ“„ PDF ë³€í™˜ ì‹œì‘: {pdf_path.name}")
        
        doc = fitz.open(pdf_path)
        images = []
        
        # í˜ì´ì§€ ìˆ˜ ì œí•œ
        total_pages = min(len(doc), max_pages)
        
        for page_num in range(total_pages):
            try:
                page = doc.load_page(page_num)
                
                # ê³ í’ˆì§ˆ ë Œë”ë§ (200 DPI)
                mat = fitz.Matrix(200/72, 200/72)
                pix = page.get_pixmap(matrix=mat)
                
                # PIL Imageë¡œ ë³€í™˜
                img_data = pix.tobytes("png")
                img = Image.open(BytesIO(img_data))
                
                # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (ìµœëŒ€ 1024x1024, í’ˆì§ˆ ìœ ì§€)
                if img.width > 1024 or img.height > 1024:
                    img.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                img_path = self.temp_dir / f"page_{page_num + 1}.png"
                img.save(img_path, "PNG", optimize=True)
                
                images.append((img, str(img_path), page_num + 1))
                print(f"   âœ… í˜ì´ì§€ {page_num + 1} ë³€í™˜ ì™„ë£Œ ({img.size[0]}x{img.size[1]})")
                
            except Exception as e:
                print(f"   âŒ í˜ì´ì§€ {page_num + 1} ë³€í™˜ ì‹¤íŒ¨: {e}")
                continue
        
        doc.close()
        print(f"ğŸ“„ ì´ {len(images)}ê°œ í˜ì´ì§€ ë³€í™˜ ì™„ë£Œ")
        return images
    
    def cleanup(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
            print("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

# ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ í´ë˜ìŠ¤
class AnalysisResultProcessor:
    """ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ë° ì¶œë ¥"""
    
    def __init__(self, output_dir: str = "analysis_results"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
    def save_results(self, results: Dict[str, Any], format_type: str = "both") -> Dict[str, str]:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_files = {}
        
        if format_type in ["json", "both"]:
            json_file = self.output_dir / f"analysis_{timestamp}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            output_files["json"] = str(json_file)
            print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥: {json_file}")
        
        if format_type in ["html", "both"]:
            html_file = self.output_dir / f"analysis_{timestamp}.html"
            html_content = self._generate_html_report(results)
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            output_files["html"] = str(html_file)
            print(f"ğŸŒ HTML ë¦¬í¬íŠ¸ ì €ì¥: {html_file}")
        
        return output_files
    
    def _generate_html_report(self, results: Dict[str, Any]) -> str:
        """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
        html_template = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ê±´ì¶• ë„ë©´ ë¶„ì„ ë¦¬í¬íŠ¸</title>
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 20px; line-height: 1.6; }
        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; }
        .section { margin: 20px 0; padding: 15px; border-left: 4px solid #667eea; background: #f8f9fa; }
        .page-analysis { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 8px; }
        .analysis-type { font-weight: bold; color: #667eea; margin-bottom: 10px; }
        .result-text { background: white; padding: 10px; border-radius: 5px; margin: 10px 0; }
        pre { background: #f4f4f4; padding: 10px; border-radius: 5px; overflow-x: auto; }
        .timestamp { color: #666; font-size: 0.9em; }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ—ï¸ ê±´ì¶• ë„ë©´ ë¶„ì„ ë¦¬í¬íŠ¸</h1>
        <p class="timestamp">ìƒì„± ì‹œê°„: {timestamp}</p>
    </div>

    <div class="section">
        <h2>ğŸ“Š ë¶„ì„ ê°œìš”</h2>
        <p><strong>ë¶„ì„ëœ í˜ì´ì§€ ìˆ˜:</strong> {page_count}</p>
        <p><strong>PDF íŒŒì¼:</strong> {pdf_file}</p>
    </div>

    {page_analyses}

    <div class="section">
        <h2>ğŸ“‹ ì „ì²´ ìš”ì•½</h2>
        <div class="result-text">
            <p>ì´ ë¦¬í¬íŠ¸ëŠ” AI ê¸°ë°˜ ê±´ì¶• ë„ë©´ ë¶„ì„ ì‹œìŠ¤í…œìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
            <p>ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
        </div>
    </div>

    <footer style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #ddd; color: #666; text-align: center;">
        <p>Generated by Architectural VLM Analysis System</p>
    </footer>
</body>
</html>
        """
        
        # í˜ì´ì§€ë³„ ë¶„ì„ ë‚´ìš© ìƒì„±
        page_analyses = ""
        page_count = 0
        
        for page_key, page_data in results.items():
            if page_key.startswith("page_"):
                page_count += 1
                page_num = page_key.split("_")[1]
                
                page_html = f"""
                <div class="page-analysis">
                    <h3>ğŸ“„ í˜ì´ì§€ {page_num} ë¶„ì„</h3>
                """
                
                for analysis_type, analysis_result in page_data.items():
                    page_html += f"""
                    <div class="analysis-type">{analysis_type}</div>
                    <div class="result-text">
                        <pre>{analysis_result}</pre>
                    </div>
                    """
                
                page_html += "</div>"
                page_analyses += page_html
        
        return html_template.format(
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            page_count=page_count,
            pdf_file=results.get("metadata", {}).get("source_file", "Unknown"),
            page_analyses=page_analyses
        )

# ë©”ì¸ ë¶„ì„ê¸° í´ë˜ìŠ¤
class ArchitecturalAnalyzer:
    """í†µí•© ê±´ì¶• ë„ë©´ ë¶„ì„ê¸°"""
    
    def __init__(self, model_name: str = None, backend: str = "transformers", verbose: bool = False):
        self.logger = setup_logging(verbose)
        self.model_name = model_name
        self.backend = backend
        
        # í™˜ê²½ ì„¤ì • ë¡œë“œ
        load_dotenv()
        self.config = get_env_config()
        
        if not self.model_name:
            self.model_name = self.config.get("MODEL_NAME", "Qwen/Qwen2.5-VL-3B-Instruct")
        
        # VLM ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.vlm_analyzer = None
        self._initialize_analyzer()
        
        # ì²˜ë¦¬ê¸°ë“¤ ì´ˆê¸°í™”
        self.pdf_processor = PDFProcessor()
        self.result_processor = AnalysisResultProcessor()
    
    def _initialize_analyzer(self):
        """VLM ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        try:
            print(f"ğŸ¤– {self.model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            use_vllm = (self.backend == "vllm")
            self.vlm_analyzer = QwenVLMAnalyzer(
                model_path=self.model_name,
                use_vllm=use_vllm
            )
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def analyze_pdf(self, pdf_path: str, max_pages: int = 5) -> Dict[str, Any]:
        """PDF ê±´ì¶• ë„ë©´ ì „ì²´ ë¶„ì„"""
        print(f"ğŸš€ ê±´ì¶• ë„ë©´ ë¶„ì„ ì‹œì‘: {pdf_path}")
        
        results = {
            "metadata": {
                "source_file": pdf_path,
                "analysis_time": datetime.now().isoformat(),
                "model_used": self.model_name,
                "backend": self.backend
            }
        }
        
        try:
            # 1. PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            images = self.pdf_processor.convert_pdf_to_images(pdf_path, max_pages)
            
            # 2. ê° í˜ì´ì§€ ë¶„ì„
            for img, img_path, page_num in images:
                print(f"\nğŸ“‹ í˜ì´ì§€ {page_num} ë¶„ì„ ì¤‘...")
                page_results = self._analyze_single_page(img, page_num)
                results[f"page_{page_num}"] = page_results
            
            # 3. ì „ì²´ ìš”ì•½
            results["summary"] = self._generate_summary(results)
            
            print("\nâœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
            return results
            
        except Exception as e:
            self.logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
        finally:
            # ì •ë¦¬
            self.pdf_processor.cleanup()
            if self.vlm_analyzer:
                self.vlm_analyzer.cleanup()
    
    def _analyze_single_page(self, image: Image.Image, page_num: int) -> Dict[str, Any]:
        """ë‹¨ì¼ í˜ì´ì§€ ë¶„ì„"""
        page_results = {}
        
        # ë¶„ì„ í”„ë¡¬í”„íŠ¸ë“¤
        analysis_prompts = {
            "ê¸°ë³¸_êµ¬ì¡°_ë¶„ì„": """
            ì´ ê±´ì¶• í‰ë©´ë„ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:
            
            1. ì „ì²´ ê±´ë¬¼ ìœ í˜• (ì•„íŒŒíŠ¸, ì£¼íƒ, ìƒê°€ ë“±)
            2. ì£¼ìš” ê³µê°„ë“¤ (ë°©, ê±°ì‹¤, ì£¼ë°©, í™”ì¥ì‹¤ ë“±)
            3. ë¬¸ê³¼ ì°½ë¬¸ì˜ ìœ„ì¹˜
            4. ë²½ì²´ì˜ êµ¬ì¡°
            5. íŠ¹ë³„í•œ ê±´ì¶•ì  íŠ¹ì§•
            
            ëª…í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.
            """,
            
            "ê³µê°„_ë¶„ì„": """
            ì´ í‰ë©´ë„ì˜ ê³µê°„ êµ¬ì„±ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
            
            {
              "rooms": [
                {"name": "ë°©ì´ë¦„", "type": "ìš©ë„", "position": "ìœ„ì¹˜", "features": ["íŠ¹ì§•1", "íŠ¹ì§•2"]}
              ],
              "circulation": "ë™ì„  ë¶„ì„",
              "total_layout": "ì „ì²´ ë ˆì´ì•„ì›ƒ íŠ¹ì§•"
            }
            """,
            
            "ì¹˜ìˆ˜_ë°_ìŠ¤ì¼€ì¼": """
            ì´ ë„ë©´ì—ì„œ ë°œê²¬í•  ìˆ˜ ìˆëŠ” ì¹˜ìˆ˜ ì •ë³´ì™€ ìŠ¤ì¼€ì¼ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
            
            1. í‘œì‹œëœ ì¹˜ìˆ˜ë“¤
            2. ë„ë©´ì˜ ìŠ¤ì¼€ì¼
            3. ì¶”ì • ë©´ì 
            4. ì£¼ìš” ì¹˜ìˆ˜ (ë°© í¬ê¸°, ë¬¸ í­ ë“±)
            
            êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """,
            
            "ì„¤ë¹„_ë°_ì‹œì„¤": """
            ì´ í‰ë©´ë„ì—ì„œ ì„¤ë¹„ì™€ ì‹œì„¤ë¬¼ì„ ì°¾ì•„ ë¶„ì„í•´ì£¼ì„¸ìš”:
            
            1. ì „ê¸° ì„¤ë¹„ (ì½˜ì„¼íŠ¸, ìŠ¤ìœ„ì¹˜, ì¡°ëª… ë“±)
            2. ê¸‰ìˆ˜/ë°°ìˆ˜ ì„¤ë¹„
            3. ì£¼ë°© ì‹œì„¤
            4. í™”ì¥ì‹¤ ì„¤ë¹„
            5. ê¸°íƒ€ íŠ¹ìˆ˜ ì‹œì„¤
            
            ê° ì‹œì„¤ì˜ ìœ„ì¹˜ì™€ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """
        }
        
        # ê° í”„ë¡¬í”„íŠ¸ë¡œ ë¶„ì„ ì‹¤í–‰
        for analysis_type, prompt in analysis_prompts.items():
            try:
                print(f"   ğŸ” {analysis_type} ì§„í–‰ ì¤‘...")
                result = self.vlm_analyzer.analyze_image(image, prompt)
                page_results[analysis_type] = result
                print(f"   âœ… {analysis_type} ì™„ë£Œ")
            except Exception as e:
                print(f"   âŒ {analysis_type} ì‹¤íŒ¨: {e}")
                page_results[analysis_type] = f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        
        return page_results
    
    def _generate_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì²´ ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        summary = {
            "total_pages": len([k for k in results.keys() if k.startswith("page_")]),
            "analysis_types_completed": [],
            "key_findings": [],
            "recommendations": []
        }
        
        # ë¶„ì„ ìœ í˜• ìˆ˜ì§‘
        for page_key, page_data in results.items():
            if page_key.startswith("page_"):
                for analysis_type in page_data.keys():
                    if analysis_type not in summary["analysis_types_completed"]:
                        summary["analysis_types_completed"].append(analysis_type)
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        summary["key_findings"] = [
            "ê±´ì¶• ë„ë©´ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            f"ì´ {summary['total_pages']}ê°œ í˜ì´ì§€ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.",
            f"{len(summary['analysis_types_completed'])}ê°€ì§€ ë¶„ì„ ìœ í˜•ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤."
        ]
        
        summary["recommendations"] = [
            "AI ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œ ì‚¬ìš©í•˜ì‹œê³ , ì •í™•í•œ ê²€í† ë¥¼ ìœ„í•´ ì „ë¬¸ê°€ ìƒë‹´ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.",
            "ë„ë©´ì˜ ìŠ¤ì¼€ì¼ê³¼ ì¹˜ìˆ˜ ì •ë³´ë¥¼ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "ì„¤ë¹„ ê³„íšì— ëŒ€í•´ì„œëŠ” ê´€ë ¨ ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        ]
        
        return summary

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ğŸ—ï¸ ê±´ì¶• ë„ë©´ ë¶„ì„ ì‹œìŠ¤í…œ")
    parser.add_argument("pdf_path", nargs="?", help="ë¶„ì„í•  PDF íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output-dir", default="analysis_results", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--format", choices=["json", "html", "both"], default="both", help="ì¶œë ¥ í˜•ì‹")
    parser.add_argument("--model", help="ì‚¬ìš©í•  ëª¨ë¸ëª…")
    parser.add_argument("--backend", choices=["vllm", "transformers"], default="transformers", help="ë°±ì—”ë“œ")
    parser.add_argument("--max-pages", type=int, default=5, help="ë¶„ì„í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    
    args = parser.parse_args()
    
    # PDF íŒŒì¼ ê²½ë¡œ ê²°ì •
    pdf_path = args.pdf_path
    if not pdf_path:
        # ê¸°ë³¸ íŒŒì¼ ì°¾ê¸°
        uploads_dir = Path("uploads")
        if uploads_dir.exists():
            pdf_files = list(uploads_dir.glob("*.pdf"))
            if pdf_files:
                pdf_path = str(pdf_files[0])
                print(f"ğŸ“ ìë™ ì„ íƒëœ íŒŒì¼: {pdf_path}")
            else:
                print("âŒ uploads ë””ë ‰í† ë¦¬ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
        else:
            print("âŒ PDF íŒŒì¼ì„ ì§€ì •í•´ì£¼ì„¸ìš”.")
            print("ì‚¬ìš©ë²•: python architectural_analyzer.py [PDFíŒŒì¼ê²½ë¡œ]")
            return
    
    if not Path(pdf_path).exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return
    
    try:
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = ArchitecturalAnalyzer(
            model_name=args.model,
            backend=args.backend,
            verbose=args.verbose
        )
        
        # ê²°ê³¼ ì²˜ë¦¬ê¸° ì„¤ì •
        analyzer.result_processor = AnalysisResultProcessor(args.output_dir)
        
        # ë¶„ì„ ì‹¤í–‰
        results = analyzer.analyze_pdf(pdf_path, args.max_pages)
        
        # ê²°ê³¼ ì €ì¥
        output_files = analyzer.result_processor.save_results(results, args.format)
        
        print("\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
        print("ğŸ“‚ ì €ì¥ëœ íŒŒì¼ë“¤:")
        for file_type, file_path in output_files.items():
            print(f"   {file_type.upper()}: {file_path}")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    # í•„ìš”í•œ importë“¤ ì¶”ê°€
    from io import BytesIO
    
    exit(main())
