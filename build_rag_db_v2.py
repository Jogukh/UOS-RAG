#!/usr/bin/env python3
"""
ê°œì„ ëœ RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ v2
ë©”íƒ€ë°ì´í„° í´ë” êµ¬ì¡°ë¥¼ ì§€ì›í•˜ê³ , í”„ë¡œì íŠ¸ë³„ ë³„ë„ DB ìƒì„±
"""

import json
import chromadb
from chromadb.utils import embedding_functions
import os
from pathlib import Path
import sys
import re
from typing import List, Dict, Any, Optional

# .env ì„¤ì • ë¡œë“œ
sys.path.append(str(Path(__file__).parent / "src"))
try:
    from env_config import get_env_config
    env_config = get_env_config()
    print(f"ğŸ“‹ .env ê¸°ë°˜ ì„¤ì • ë¡œë“œë¨ - LLM: {env_config.llm_provider_config.provider}, ì„ë² ë”©: {env_config.embedding_config.provider}")
except ImportError:
    print("âš ï¸  env_configë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    env_config = None

# ìƒìˆ˜ ì •ì˜
UPLOADS_ROOT_DIR = Path("uploads")
CHROMA_DB_PATH = "./chroma_db"

class RAGDatabaseBuilder:
    """RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, db_path: str = CHROMA_DB_PATH):
        self.db_path = db_path
        self.client = None
        self.embedding_function = None
        self._init_client()
    
    def _init_client(self):
        """ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not os.path.exists(self.db_path):
            os.makedirs(self.db_path)
        
        self.client = chromadb.PersistentClient(path=self.db_path)
        
        # í™˜ê²½ ì„¤ì •ì— ë”°ë¥¸ ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™”
        if env_config and env_config.embedding_config.provider == "openai":
            print(f"ğŸ”§ OpenAI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©: {env_config.embedding_config.openai_model}")
            self.embedding_function = embedding_functions.OpenAIEmbeddingFunction(
                api_key=env_config.llm_provider_config.openai_api_key,
                model_name=env_config.embedding_config.openai_model
            )
        else:
            # fallback: SentenceTransformer ì‚¬ìš©
            fallback_model = "all-MiniLM-L6-v2"
            print(f"ğŸ”§ SentenceTransformer ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©: {fallback_model}")
            self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name=fallback_model
            )
        
        print(f"âœ… ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.db_path}")
    
    def _normalize_collection_name(self, project_name: str) -> str:
        """ì»¬ë ‰ì…˜ ì´ë¦„ì„ ChromaDB ê·œì¹™ì— ë§ê²Œ ì •ê·œí™”"""
        # í•œê¸€ì„ ì˜ì–´ë¡œ ë³€í™˜í•˜ëŠ” ê°„ë‹¨í•œ ë§¤í•‘
        korean_to_english = {
            "ë¶€ì‚°": "busan",
            "ì¥ì•ˆ": "jangan", 
            "í”„ë¡œì íŠ¸": "project",
            "ì •ë³´": "info",
            "ë„ë©´": "drawing"
        }
        
        # í•œê¸€ì„ ì˜ì–´ë¡œ ë³€í™˜
        translated_name = project_name
        for korean, english in korean_to_english.items():
            translated_name = translated_name.replace(korean, english)
        
        # ê¸°ë³¸ ë³€í™˜
        collection_name = f"{translated_name}".replace(" ", "_").replace("-", "_").lower()
        
        # ASCII ë¬¸ìì™€ ìˆ«ì, ì–¸ë”ìŠ¤ì½”ì–´ë§Œ í—ˆìš©
        collection_name = "".join(c if (c.isascii() and c.isalnum()) or c == "_" else "_" for c in collection_name)
        
        # ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
        collection_name = re.sub(r'_+', '_', collection_name)
        
        # ê¸¸ì´ ì œí•œ (3-63ì)
        collection_name = collection_name[:63]
        
        # ì‹œì‘ê³¼ ëì´ ì˜ë¬¸/ìˆ«ìì¸ì§€ í™•ì¸
        if not collection_name or not collection_name[0].isalnum():
            collection_name = "proj_" + collection_name.lstrip('_')
        if not collection_name[-1].isalnum():
            collection_name = collection_name.rstrip('_') + "_coll"
        
        return collection_name
    
    def check_existing_collection(self, collection_name: str) -> str:
        """ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸ ë° ì‚¬ìš©ì ì„ íƒ"""
        try:
            collection = self.client.get_collection(collection_name)
            count = collection.count()
            
            if count > 0:
                print(f"\nâš ï¸  ì»¬ë ‰ì…˜ '{collection_name}'ì— ì´ë¯¸ {count}ê°œì˜ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤.")
                print("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
                print("1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆë¡œ êµ¬ì¶• (ê¶Œì¥)")
                print("2. ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€")
                print("3. ì·¨ì†Œ")
                
                while True:
                    choice = input("\nì„ íƒ (1/2/3): ").strip()
                    
                    if choice == "1":
                        print(f"ğŸ—‘ï¸  ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' ì‚­ì œ ì¤‘...")
                        self.client.delete_collection(collection_name)
                        print("âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        return "recreate"
                    
                    elif choice == "2":
                        print(f"ğŸ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ì— ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")
                        return "append"
                    
                    elif choice == "3":
                        print("âŒ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        return "cancel"
                    
                    else:
                        print("ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš” (1, 2, 3)")
            else:
                print(f"âœ… ì»¬ë ‰ì…˜ '{collection_name}'ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤.")
                # ë¹ˆ ì»¬ë ‰ì…˜ë„ ì‚­ì œ í›„ ì¬ìƒì„±
                self.client.delete_collection(collection_name)
                return "recreate"
                
        except Exception as e:
            # ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
            print(f"ğŸ“ ìƒˆ ì»¬ë ‰ì…˜ '{collection_name}'ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            return "create"
    
    def load_metadata_from_folder(self, metadata_folder: Path) -> List[Dict[str, Any]]:
        """ë©”íƒ€ë°ì´í„° í´ë”ì—ì„œ ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ"""
        metadata_list = []
        metadata_files = list(metadata_folder.glob("*_metadata.json"))
        
        if not metadata_files:
            print(f"âŒ ë©”íƒ€ë°ì´í„° JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_folder}")
            return []
        
        print(f"ğŸ“„ ë°œê²¬ëœ ë©”íƒ€ë°ì´í„° íŒŒì¼: {len(metadata_files)}ê°œ")
        
        for metadata_file in metadata_files:
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    drawing_metadata = json.load(f)
                
                # íŒŒì¼ëª…ì—ì„œ ë„ë©´ ì •ë³´ ì¶”ì¶œ
                file_stem = metadata_file.stem.replace('_metadata', '')
                drawing_metadata['source_file'] = metadata_file.name
                drawing_metadata['file_stem'] = file_stem
                
                metadata_list.append(drawing_metadata)
                
            except json.JSONDecodeError:
                print(f"    âŒ {metadata_file.name}: JSON íŒŒì‹± ì˜¤ë¥˜")
            except Exception as e:
                print(f"    âŒ {metadata_file.name}: ì²˜ë¦¬ ì˜¤ë¥˜ - {e}")
        
        return metadata_list
    
    def process_metadata_for_rag(self, metadata_list: List[Dict[str, Any]], project_name: str) -> tuple:
        """ë©”íƒ€ë°ì´í„°ë¥¼ RAGìš©ìœ¼ë¡œ ê°€ê³µ (ì •ë³´ ë³´ì¡´)"""
        documents = []
        metadatas = []
        ids = []
        
        for i, drawing_metadata in enumerate(metadata_list):
            try:
                file_stem = drawing_metadata.get('file_stem', f'doc_{i+1}')
                
                # Self-Query í˜•ì‹ ë˜ëŠ” ê¸°ì¡´ í˜•ì‹ ì²˜ë¦¬
                if isinstance(drawing_metadata, dict):
                    # Self-Query í˜•ì‹ì¸ ê²½ìš°
                    if "page_content" in drawing_metadata or "content" in drawing_metadata:
                        content = drawing_metadata.get("page_content", drawing_metadata.get("content", ""))
                        metadata = drawing_metadata.get("metadata", {})
                    else:
                        # ê¸°ì¡´ í˜•ì‹ì¸ ê²½ìš°
                        content = drawing_metadata.get("content", "")
                        metadata = drawing_metadata.copy()
                        # content í‚¤ ì œê±° (ë©”íƒ€ë°ì´í„°ì—ì„œ)
                        metadata.pop("content", None)
                    
                    # ìƒˆë¡œìš´ ì²˜ë¦¬ ë©”ì„œë“œ ì‚¬ìš© (ì •ë³´ ë³´ì¡´)
                    enhanced_content, cleaned_metadata, doc_id = self._prepare_document_for_chroma(
                        content, metadata, project_name, file_stem, i
                    )
                    
                    documents.append(enhanced_content)
                    metadatas.append(cleaned_metadata)
                    ids.append(doc_id)
                    
                    print(f"    âœ… ì²˜ë¦¬ ì™„ë£Œ: {file_stem}")
                
                else:
                    print(f"    âš ï¸  {file_stem}: ì˜¬ë°”ë¥´ì§€ ì•Šì€ ë©”íƒ€ë°ì´í„° í˜•ì‹")
                    
            except Exception as e:
                print(f"    âŒ í•­ëª© {i} ({file_stem}): ì²˜ë¦¬ ì˜¤ë¥˜ - {e}")
                import traceback
                traceback.print_exc()
        
        return documents, metadatas, ids
    
    def build_project_rag(self, project_name: str, metadata_folder_path: Optional[Path] = None) -> bool:
        """ë‹¨ì¼ í”„ë¡œì íŠ¸ì˜ RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"""
        print(f"\nğŸ—ï¸  í”„ë¡œì íŠ¸ '{project_name}' RAG DB êµ¬ì¶• ì‹œì‘...")
        
        # ë©”íƒ€ë°ì´í„° í´ë” ê²½ë¡œ ì„¤ì •
        if metadata_folder_path is None:
            metadata_folder_path = UPLOADS_ROOT_DIR / project_name / "metadata"
        else:
            metadata_folder_path = Path(metadata_folder_path)
        
        print(f"ğŸ“ ë©”íƒ€ë°ì´í„° í´ë”: {metadata_folder_path}")
        
        if not metadata_folder_path.exists():
            print(f"âŒ ë©”íƒ€ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_folder_path}")
            return False
        
        # ì»¬ë ‰ì…˜ ì´ë¦„ ì •ê·œí™”
        collection_name = self._normalize_collection_name(project_name)
        print(f"ğŸ—ƒï¸  ì»¬ë ‰ì…˜ëª…: {collection_name}")
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸ ë° ì²˜ë¦¬
        action = self.check_existing_collection(collection_name)
        if action == "cancel":
            return False
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        metadata_list = self.load_metadata_from_folder(metadata_folder_path)
        if not metadata_list:
            return False
        
        # RAGìš© ë°ì´í„° ê°€ê³µ
        documents, metadatas, ids = self.process_metadata_for_rag(metadata_list, project_name)
        
        if not documents:
            print(f"  âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        print(f"  ğŸ“„ ì²˜ë¦¬ëœ ë¬¸ì„œ: {len(documents)}ê°œ")
        
        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        try:
            if action in ["recreate", "create"]:
                collection = self.client.get_or_create_collection(
                    name=collection_name,
                    embedding_function=self.embedding_function,
                    metadata={"hnsw:space": "cosine"}
                )
            else:  # append
                collection = self.client.get_collection(
                    name=collection_name,
                    embedding_function=self.embedding_function
                )
            
            print(f"  âœ… ì»¬ë ‰ì…˜ '{collection_name}' ì¤€ë¹„ ì™„ë£Œ")
        except Exception as e:
            print(f"  âŒ ì»¬ë ‰ì…˜ ìƒì„±/ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ({collection_name}): {e}")
            return False
        
        # ë¬¸ì„œ ì¶”ê°€
        try:
            print(f"  ğŸ“ {len(documents)}ê°œ ë¬¸ì„œë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€ ì¤‘...")
            
            # ë°°ì¹˜ ì²˜ë¦¬ (í•œ ë²ˆì— ë„ˆë¬´ ë§ì´ ì²˜ë¦¬í•˜ì§€ ì•Šë„ë¡)
            batch_size = 50
            for i in range(0, len(documents), batch_size):
                batch_docs = documents[i:i+batch_size]
                batch_metas = metadatas[i:i+batch_size]
                batch_ids = ids[i:i+batch_size]
                
                collection.add(
                    documents=batch_docs,
                    metadatas=batch_metas,
                    ids=batch_ids
                )
                
                print(f"    ğŸ“„ {min(i+batch_size, len(documents))}/{len(documents)} ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ")
            
            final_count = collection.count()
            print(f"  âœ… RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ! ì´ ë¬¸ì„œ ìˆ˜: {final_count}")
            return True
            
        except Exception as e:
            print(f"  âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def list_collections(self) -> List[str]:
        """ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡ ë°˜í™˜"""
        try:
            collections = self.client.list_collections()
            return [col.name for col in collections]
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_collection_info(self, collection_name: str) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ì •ë³´ ë°˜í™˜"""
        try:
            collection = self.client.get_collection(collection_name)
            count = collection.count()
            return {"name": collection_name, "count": count}
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ '{collection_name}' ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def _prepare_document_for_chroma(self, content: str, metadata: Dict[str, Any], project_name: str, file_stem: str, index: int = 0) -> tuple[str, Dict[str, Any], str]:
        """ChromaDBì— ì €ì¥í•  ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ì¤€ë¹„ (ì •ë³´ ë³´ì¡´)"""
        
        # ë©”ì¸ ì»¨í…ì¸  ì¤€ë¹„
        if isinstance(content, dict):
            main_content = content.get("page_content", content.get("content", ""))
            doc_metadata = content.get("metadata", {})
        else:
            main_content = str(content) if content else ""
            doc_metadata = metadata
        
        # í’ë¶€í•œ ì»¨í…ì¸  ìƒì„± (ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ)
        enhanced_content = self._create_enhanced_content(main_content, doc_metadata, project_name)
        
        # ChromaDB í˜¸í™˜ ë©”íƒ€ë°ì´í„° ìƒì„± (ì •ë³´ ë³´ì¡´)
        chroma_metadata = self._clean_metadata_for_chroma(doc_metadata)
        
        # ê³ ìœ  ID ìƒì„±
        doc_id = self._generate_document_id(doc_metadata, project_name, file_stem, index)
        
        return enhanced_content, chroma_metadata, doc_id
    
    def _create_enhanced_content(self, main_content: str, metadata: Dict[str, Any], project_name: str) -> str:
        """ê²€ìƒ‰ ì„±ëŠ¥ì„ ìœ„í•œ í’ë¶€í•œ ì»¨í…ì¸  ìƒì„± (ëª¨ë“  ì •ë³´ í™œìš©)"""
        content_parts = []
        
        # ë©”ì¸ ì»¨í…ì¸ 
        if main_content:
            content_parts.append(main_content)
        
        # í”„ë¡œì íŠ¸ ì •ë³´
        content_parts.append(f"í”„ë¡œì íŠ¸: {project_name}")
        
        # ë„ë©´ ê¸°ë³¸ ì •ë³´
        if metadata.get("drawing_title"):
            content_parts.append(f"ë„ë©´ëª…: {metadata['drawing_title']}")
        
        if metadata.get("drawing_number") and metadata["drawing_number"] != "ì •ë³´ ì—†ìŒ":
            content_parts.append(f"ë„ë©´ë²ˆí˜¸: {metadata['drawing_number']}")
        
        if metadata.get("drawing_type"):
            content_parts.append(f"ë„ë©´ìœ í˜•: {metadata['drawing_type']}")
        
        if metadata.get("drawing_category"):
            content_parts.append(f"ë„ë©´ë¶„ë¥˜: {metadata['drawing_category']}")
        
        # êµ¬ì¡°/ê±´ì¶• ì •ë³´
        if metadata.get("structure_type") and metadata["structure_type"] != "ì •ë³´ ì—†ìŒ":
            content_parts.append(f"êµ¬ì¡°í˜•ì‹: {metadata['structure_type']}")
        
        if metadata.get("main_use") and metadata["main_use"] != "ì •ë³´ ì—†ìŒ":
            content_parts.append(f"ì£¼ìš©ë„: {metadata['main_use']}")
        
        # ë©´ì  ì •ë³´
        area_info = []
        if metadata.get("building_area"):
            area_info.append(f"ê±´ì¶•ë©´ì  {metadata['building_area']}ã¡")
        if metadata.get("total_floor_area"):
            area_info.append(f"ì—°ë©´ì  {metadata['total_floor_area']}ã¡")
        if metadata.get("land_area"):
            area_info.append(f"ëŒ€ì§€ë©´ì  {metadata['land_area']}ã¡")
        
        if area_info:
            content_parts.append(" ".join(area_info))
        
        # ì¸µìˆ˜ ì •ë³´
        floor_info = []
        if metadata.get("floors_above"):
            floor_info.append(f"ì§€ìƒ {metadata['floors_above']}ì¸µ")
        if metadata.get("floors_below"):
            floor_info.append(f"ì§€í•˜ {metadata['floors_below']}ì¸µ")
        
        if floor_info:
            content_parts.append(" ".join(floor_info))
        
        # ë¶€ê°€ ì •ë³´
        if metadata.get("parking_spaces"):
            content_parts.append(f"ì£¼ì°¨ëŒ€ìˆ˜: {metadata['parking_spaces']}ëŒ€")
        
        if metadata.get("apartment_units"):
            content_parts.append(f"ì„¸ëŒ€ìˆ˜: {metadata['apartment_units']}ì„¸ëŒ€")
        
        # ì„¤ê³„/ì‹œê³µ ì •ë³´
        if metadata.get("design_firm") and metadata["design_firm"] != "ì •ë³´ ì—†ìŒ":
            content_parts.append(f"ì„¤ê³„ì‚¬: {metadata['design_firm']}")
        
        if metadata.get("construction_firm") and metadata["construction_firm"] != "ì •ë³´ ì—†ìŒ":
            content_parts.append(f"ì‹œê³µì‚¬: {metadata['construction_firm']}")
        
        # Legacy ë°ì´í„° í™œìš© (ìƒì„¸ ì •ë³´)
        if metadata.get("legacy_data"):
            legacy_data = metadata["legacy_data"]
            
            # ë„ë©´ ìƒì„¸ ì •ë³´
            if legacy_data.get("draw_info"):
                for key, value in legacy_data["draw_info"].items():
                    if value and str(value).strip() and str(value) != "ì •ë³´ ì—†ìŒ":
                        content_parts.append(f"{key}: {value}")
            
            # ì£¼ìš” í‚¤ì›Œë“œ (ìƒìœ„ 30ê°œ)
            if legacy_data.get("word_counts"):
                top_words = sorted(legacy_data["word_counts"].items(), 
                                 key=lambda x: x[1], reverse=True)[:30]
                # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§
                meaningful_words = []
                for word, count in top_words:
                    if (len(word.strip()) > 1 and 
                        word.strip() not in ["", "NOTE", "LEVEL"] and
                        count > 1):
                        meaningful_words.append(word)
                
                if meaningful_words:
                    content_parts.append(f"ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(meaningful_words)}")
        
        return "\n".join(content_parts)
    
    def _clean_metadata_for_chroma(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """ChromaDBì— ì €ì¥ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë©”íƒ€ë°ì´í„° ì •ë¦¬ (ì •ë³´ ë³´ì¡´)"""
        cleaned = {}
        
        # ê¸°ë³¸ í•„ë“œë“¤ (ChromaDB í˜¸í™˜)
        basic_fields = [
            "drawing_number", "drawing_title", "drawing_type", "drawing_category",
            "project_name", "project_address", "file_name", "page_number",
            "has_tables", "has_images", "structure_type", "main_use", 
            "design_firm", "construction_firm", "extracted_at", "extraction_method"
        ]
        
        # ìˆ«ì í•„ë“œë“¤
        numeric_fields = [
            "land_area", "building_area", "total_floor_area", "building_height",
            "floors_above", "floors_below", "parking_spaces", "apartment_units",
            "building_coverage_ratio", "floor_area_ratio"
        ]
        
        # ê¸°ë³¸ í•„ë“œ ì²˜ë¦¬
        for field in basic_fields:
            value = metadata.get(field)
            if value is not None and value != "ì •ë³´ ì—†ìŒ" and value != "":
                cleaned[field] = str(value)
        
        # ìˆ«ì í•„ë“œ ì²˜ë¦¬
        for field in numeric_fields:
            value = metadata.get(field)
            if value is not None and value != 0:
                cleaned[field] = float(value) if isinstance(value, (int, float)) else value
        
        # Boolean í•„ë“œ ì²˜ë¦¬
        for field in ["has_tables", "has_images"]:
            value = metadata.get(field)
            if value is not None:
                cleaned[field] = bool(value)
        
        # ë¦¬ìŠ¤íŠ¸ í•„ë“œ ì²˜ë¦¬ (room_list ë“±)
        if metadata.get("room_list"):
            room_list = metadata["room_list"]
            if isinstance(room_list, list) and room_list:
                cleaned["room_count"] = len(room_list)
                cleaned["room_types"] = ", ".join(str(room) for room in room_list[:10])  # ìƒìœ„ 10ê°œ
        
        # Legacy ë°ì´í„°ì—ì„œ ìœ ìš©í•œ í†µê³„ ì •ë³´ ì¶”ì¶œ
        if metadata.get("legacy_data"):
            legacy_data = metadata["legacy_data"]
            
            # ì´ë¯¸ì§€ ì •ë³´
            if legacy_data.get("image_paths"):
                cleaned["image_count"] = len(legacy_data["image_paths"])
            
            # í‚¤ì›Œë“œ í†µê³„
            if legacy_data.get("word_counts"):
                word_counts = legacy_data["word_counts"]
                cleaned["unique_keywords"] = len(word_counts)
                cleaned["total_keyword_frequency"] = sum(word_counts.values())
                
                # ìµœê³  ë¹ˆë„ í‚¤ì›Œë“œë“¤
                top_5_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                if top_5_words:
                    cleaned["top_keywords"] = ", ".join([word for word, count in top_5_words])
            
            # ë„ë©´ ìƒì„¸ ì •ë³´
            if legacy_data.get("draw_info"):
                for key, value in legacy_data["draw_info"].items():
                    if value and str(value).strip() and str(value) != "ì •ë³´ ì—†ìŒ":
                        cleaned[f"draw_{key.lower()}"] = str(value)
        
        return cleaned
    
    def _generate_document_id(self, metadata: Dict[str, Any], project_name: str, file_stem: str, index: int) -> str:
        """ê³ ìœ  ë¬¸ì„œ ID ìƒì„±"""
        # ë„ë©´ ë²ˆí˜¸ ì‚¬ìš© (ìˆëŠ” ê²½ìš°)
        drawing_num = metadata.get("drawing_number", "")
        if drawing_num and drawing_num != "ì •ë³´ ì—†ìŒ":
            base_id = f"{project_name}_{drawing_num}"
        else:
            base_id = f"{project_name}_{file_stem}"
        
        # í˜ì´ì§€ ë²ˆí˜¸ ì¶”ê°€
        page_num = metadata.get("page_number", 1)
        if page_num > 1:
            base_id += f"_p{page_num}"
        
        # ì¸ë±ìŠ¤ ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
        if index > 0:
            base_id += f"_{index}"
        
        # ì•ˆì „í•œ IDë¡œ ë³€í™˜
        safe_id = re.sub(r'[^\w\-_]', '_', base_id)
        return safe_id


def build_all_projects_rag():
    """ëª¨ë“  í”„ë¡œì íŠ¸ì˜ RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"""
    builder = RAGDatabaseBuilder()
    
    print("ğŸ” í”„ë¡œì íŠ¸ í´ë” ìŠ¤ìº” ì¤‘...")
    
    if not UPLOADS_ROOT_DIR.exists():
        print(f"âŒ uploads í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {UPLOADS_ROOT_DIR}")
        return
    
    # í”„ë¡œì íŠ¸ í´ë” ì°¾ê¸° (metadata í•˜ìœ„í´ë”ê°€ ìˆëŠ” í´ë”)
    project_folders = []
    for item in UPLOADS_ROOT_DIR.iterdir():
        if item.is_dir():
            metadata_folder = item / "metadata"
            if metadata_folder.exists() and any(metadata_folder.glob("*_metadata.json")):
                project_folders.append(item)
    
    if not project_folders:
        print("âŒ ë©”íƒ€ë°ì´í„° í´ë”ê°€ ìˆëŠ” í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ë°œê²¬ëœ í”„ë¡œì íŠ¸: {len(project_folders)}ê°œ")
    for folder in project_folders:
        print(f"  - {folder.name}")
    
    # ê° í”„ë¡œì íŠ¸ë³„ë¡œ RAG DB êµ¬ì¶•
    success_count = 0
    for project_folder in project_folders:
        project_name = project_folder.name
        metadata_folder = project_folder / "metadata"
        
        if builder.build_project_rag(project_name, metadata_folder):
            success_count += 1
        else:
            print(f"âŒ í”„ë¡œì íŠ¸ '{project_name}' RAG DB êµ¬ì¶• ì‹¤íŒ¨")
    
    print(f"\nğŸ‰ RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {success_count}/{len(project_folders)}ê°œ í”„ë¡œì íŠ¸")
    
    # ìµœì¢… ì»¬ë ‰ì…˜ ëª©ë¡ ì¶œë ¥
    collections = builder.list_collections()
    if collections:
        print(f"\nğŸ“š ìƒì„±ëœ ì»¬ë ‰ì…˜ ëª©ë¡:")
        for collection_name in collections:
            info = builder.get_collection_info(collection_name)
            if info:
                print(f"  - {collection_name}: {info.get('count', 0)}ê°œ ë¬¸ì„œ")


def build_specific_project_rag(project_name: str):
    """íŠ¹ì • í”„ë¡œì íŠ¸ì˜ RAG ë°ì´í„°ë² ì´ìŠ¤ë§Œ êµ¬ì¶•"""
    builder = RAGDatabaseBuilder()
    
    project_folder = UPLOADS_ROOT_DIR / project_name
    if not project_folder.exists():
        print(f"âŒ í”„ë¡œì íŠ¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_folder}")
        return False
    
    metadata_folder = project_folder / "metadata"
    if not metadata_folder.exists():
        print(f"âŒ ë©”íƒ€ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_folder}")
        return False
    
    return builder.build_project_rag(project_name, metadata_folder)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•")
    parser.add_argument("--project", type=str, help="íŠ¹ì • í”„ë¡œì íŠ¸ë§Œ êµ¬ì¶• (í”„ë¡œì íŠ¸ ì´ë¦„)")
    parser.add_argument("--list", action="store_true", help="ê¸°ì¡´ ì»¬ë ‰ì…˜ ëª©ë¡ ì¶œë ¥")
    
    args = parser.parse_args()
    
    if args.list:
        builder = RAGDatabaseBuilder()
        collections = builder.list_collections()
        print("ğŸ“š ê¸°ì¡´ ì»¬ë ‰ì…˜ ëª©ë¡:")
        for collection_name in collections:
            info = builder.get_collection_info(collection_name)
            if info:
                print(f"  - {collection_name}: {info.get('count', 0)}ê°œ ë¬¸ì„œ")
    
    elif args.project:
        print(f"ğŸš€ í”„ë¡œì íŠ¸ '{args.project}' RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        if build_specific_project_rag(args.project):
            print("ğŸ‰ RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    else:
        print("ğŸš€ ëª¨ë“  í”„ë¡œì íŠ¸ RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        build_all_projects_rag()
