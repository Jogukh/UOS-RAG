#!/usr/bin/env python3
"""
LangGraph ê¸°ë°˜ ê±´ì¶• ë„ë©´ ë¶„ì„ ì›Œí¬í”Œë¡œìš°
Sequ    def __init__(self, llm_model: str = "Qwen/Qwen3-Reranker-4B"):ntial Thinking, Context7, Tavily ë“± MCP ë„êµ¬ë“¤ì„ í™œìš©í•œ ì²´ì¸ êµ¬ì„±
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, TypedDict, Annotated

try:
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain_core.tools import tool
    from langchain_community.llms import Ollama
    from langchain_community.chat_models import ChatOllama
    from langgraph.graph import StateGraph, END
    from langgraph.prebuilt import ToolNode, tools_condition
    from langgraph.checkpoint.sqlite import SqliteSaver
    HAS_LANGGRAPH = True
except ImportError as e:
    print(f"LangChain/LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    print("pip install langchain langchain-core langchain-community langgraph ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    HAS_LANGGRAPH = False

logger = logging.getLogger(__name__)

# ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì •ì˜
class ArchitecturalWorkflowState(TypedDict):
    """ê±´ì¶• ë„ë©´ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    # ì…ë ¥ ë°ì´í„°
    project_name: str
    pdf_files: List[str]
    query: Optional[str]
    
    # ë¶„ì„ ê²°ê³¼
    extracted_texts: List[Dict[str, Any]]
    metadata_results: List[Dict[str, Any]]  
    relationships: List[Dict[str, Any]]
    rag_db_status: Dict[str, Any]
    
    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬
    messages: List[Any]
    
    # í˜„ì¬ ë‹¨ê³„
    current_step: str
    completed_steps: List[str]
    
    # ì˜¤ë¥˜ ì •ë³´
    errors: List[str]
    
    # ìµœì¢… ê²°ê³¼
    final_results: Dict[str, Any]

class ArchitecturalAnalysisWorkflow:
    """LangGraph ê¸°ë°˜ ê±´ì¶• ë„ë©´ ë¶„ì„ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, llm_model: str = "Qwen/Qwen2.5-3B-Instruct"):
        """
        Args:
            llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸ (vLLM ê¸°ë°˜, GPU ì‚¬ìš©)
        """
        self.llm_model = llm_model
        self.llm = None
        self.sampling_params = None
        self.workflow = None
        self.app = None
        
        if HAS_LANGGRAPH:
            self._initialize_llm()
            self._build_workflow()
            
    def _initialize_llm(self):
        """GPUë¥¼ ì‚¬ìš©í•˜ì—¬ vLLM ì´ˆê¸°í™”"""
        try:
            # GPU ì‚¬ìš© í™•ì¸
            import torch
            if not torch.cuda.is_available():
                raise RuntimeError("CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. GPUê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            print(f"ğŸ”¥ GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
            
            # vLLM import
            from vllm import LLM, SamplingParams
            
            # vLLM GPU ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™” (Qwen3-Reranker-4Bì— ìµœì í™”)
            self.llm = LLM(
                model=self.llm_model,
                tensor_parallel_size=1,
                gpu_memory_utilization=0.9,  # GPU ë©”ëª¨ë¦¬ 90% ì‚¬ìš©
                max_model_len=4096,  # 4B ëª¨ë¸ì— ì í•©í•œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
                dtype="bfloat16",  # bfloat16ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
                trust_remote_code=True,
                enforce_eager=True,  # GPU ì‚¬ìš© ê°•ì œ
            )
            
            self.sampling_params = SamplingParams(
                temperature=0.3,
                top_p=0.8,
                max_tokens=2048,
                repetition_penalty=1.02,
                stop=["<|endoftext|>", "<|im_end|>"]
            )
            
            print("âœ… vLLM GPU ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info(f"vLLM ëª¨ë¸ '{self.llm_model}' GPU ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ vLLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.error(f"vLLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
    def _build_workflow(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        
        # ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±
        workflow = StateGraph(ArchitecturalWorkflowState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("extract_texts", self.extract_texts_node)
        workflow.add_node("extract_metadata", self.extract_metadata_node)
        workflow.add_node("infer_relationships", self.infer_relationships_node)
        workflow.add_node("build_rag_db", self.build_rag_db_node)
        workflow.add_node("query_system", self.query_system_node)
        workflow.add_node("generate_report", self.generate_report_node)
        
        # ì—£ì§€ ì •ì˜ (ë‹¨ê³„ë³„ ì‹¤í–‰ ìˆœì„œ)
        workflow.set_entry_point("extract_texts")
        workflow.add_edge("extract_texts", "extract_metadata")
        workflow.add_edge("extract_metadata", "infer_relationships")
        workflow.add_edge("infer_relationships", "build_rag_db")
        workflow.add_conditional_edges(
            "build_rag_db",
            self._should_query,
            {
                "query": "query_system",
                "report": "generate_report"
            }
        )
        workflow.add_edge("query_system", "generate_report")
        workflow.add_edge("generate_report", END)
        
        # ì²´í¬í¬ì¸í„° ì„¤ì • (ìƒíƒœ ì €ì¥)
        checkpointer = SqliteSaver.from_conn_string(":memory:")
        
        # ì•± ì»´íŒŒì¼
        self.app = workflow.compile(checkpointer=checkpointer)
        
        logger.info("LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± ì™„ë£Œ")
    
    def _should_query(self, state: ArchitecturalWorkflowState) -> str:
        """ì¿¼ë¦¬ ì‹¤í–‰ ì—¬ë¶€ ê²°ì •"""
        if state.get("query"):
            return "query"
        return "report"
    
    async def extract_texts_node(self, state: ArchitecturalWorkflowState) -> ArchitecturalWorkflowState:
        """1ë‹¨ê³„: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        
        messages = state.get("messages", [])
        messages.append(SystemMessage(content="PDF í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤."))
        
        try:
            # analyze_uploads_new.py ì‹¤í–‰ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ëª¨ë“ˆ import)
            import subprocess
            result = subprocess.run(
                ["python", "analyze_uploads_new.py"], 
                capture_output=True, 
                text=True,
                cwd=Path(__file__).parent.parent
            )
            
            if result.returncode == 0:
                # uploads_analysis_results.json ë¡œë“œ
                results_file = Path(__file__).parent.parent / "uploads_analysis_results.json"
                if results_file.exists():
                    with open(results_file, 'r', encoding='utf-8') as f:
                        extracted_texts = json.load(f)
                else:
                    extracted_texts = []
                
                messages.append(AIMessage(content=f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(extracted_texts)}ê°œ í”„ë¡œì íŠ¸"))
                
                return {
                    **state,
                    "extracted_texts": extracted_texts,
                    "current_step": "extract_texts",
                    "completed_steps": state.get("completed_steps", []) + ["extract_texts"],
                    "messages": messages
                }
            else:
                error_msg = f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}"
                messages.append(AIMessage(content=error_msg))
                
                return {
                    **state,
                    "errors": state.get("errors", []) + [error_msg],
                    "messages": messages
                }
                
        except Exception as e:
            error_msg = f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            messages.append(AIMessage(content=error_msg))
            
            return {
                **state,
                "errors": state.get("errors", []) + [error_msg],
                "messages": messages
            }
    
    async def extract_metadata_node(self, state: ArchitecturalWorkflowState) -> ArchitecturalWorkflowState:
        """2ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        
        messages = state.get("messages", [])
        messages.append(SystemMessage(content="ë©”íƒ€ë°ì´í„° ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤."))
        
        try:
            # extract_metadata.py ì‹¤í–‰
            import subprocess
            result = subprocess.run(
                ["python", "extract_metadata.py"], 
                capture_output=True, 
                text=True,
                cwd=Path(__file__).parent.parent
            )
            
            if result.returncode == 0:
                # ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤ í™•ì¸
                uploads_dir = Path(__file__).parent.parent / "uploads"
                metadata_files = list(uploads_dir.glob("**/project_metadata_*.json"))
                
                metadata_results = []
                for file_path in metadata_files:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        metadata_results.append(json.load(f))
                
                messages.append(AIMessage(content=f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(metadata_results)}ê°œ í”„ë¡œì íŠ¸"))
                
                return {
                    **state,
                    "metadata_results": metadata_results,
                    "current_step": "extract_metadata", 
                    "completed_steps": state.get("completed_steps", []) + ["extract_metadata"],
                    "messages": messages
                }
            else:
                error_msg = f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {result.stderr}"
                messages.append(AIMessage(content=error_msg))
                
                return {
                    **state,
                    "errors": state.get("errors", []) + [error_msg],
                    "messages": messages
                }
                
        except Exception as e:
            error_msg = f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            messages.append(AIMessage(content=error_msg))
            
            return {
                **state,
                "errors": state.get("errors", []) + [error_msg],
                "messages": messages
            }
    
    async def infer_relationships_node(self, state: ArchitecturalWorkflowState) -> ArchitecturalWorkflowState:
        """3ë‹¨ê³„: ê´€ê³„ ì¶”ë¡ """
        
        messages = state.get("messages", [])
        messages.append(SystemMessage(content="ë„ë©´ ê°„ ê´€ê³„ ì¶”ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤."))
        
        try:
            # infer_relationships.py ì‹¤í–‰ (LLM ì‚¬ìš©)
            import subprocess
            result = subprocess.run(
                ["python", "infer_relationships.py", "--use-llm", "--max-drawings-for-llm", "100"], 
                capture_output=True, 
                text=True,
                cwd=Path(__file__).parent.parent
            )
            
            if result.returncode == 0:
                # ê´€ê³„ íŒŒì¼ë“¤ í™•ì¸
                uploads_dir = Path(__file__).parent.parent / "uploads"
                relationship_files = list(uploads_dir.glob("**/*_drawing_relationships.json"))
                
                relationships = []
                for file_path in relationship_files:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        relationships.append(json.load(f))
                
                messages.append(AIMessage(content=f"ê´€ê³„ ì¶”ë¡  ì™„ë£Œ: {len(relationships)}ê°œ í”„ë¡œì íŠ¸"))
                
                return {
                    **state,
                    "relationships": relationships,
                    "current_step": "infer_relationships",
                    "completed_steps": state.get("completed_steps", []) + ["infer_relationships"],
                    "messages": messages
                }
            else:
                error_msg = f"ê´€ê³„ ì¶”ë¡  ì‹¤íŒ¨: {result.stderr}"
                messages.append(AIMessage(content=error_msg))
                
                return {
                    **state,
                    "errors": state.get("errors", []) + [error_msg],
                    "messages": messages
                }
                
        except Exception as e:
            error_msg = f"ê´€ê³„ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜: {str(e)}"
            messages.append(AIMessage(content=error_msg))
            
            return {
                **state,
                "errors": state.get("errors", []) + [error_msg],
                "messages": messages
            }
    
    async def build_rag_db_node(self, state: ArchitecturalWorkflowState) -> ArchitecturalWorkflowState:
        """4ë‹¨ê³„: RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"""
        
        messages = state.get("messages", [])
        messages.append(SystemMessage(content="RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤."))
        
        try:
            # build_rag_db.py ì‹¤í–‰
            import subprocess
            result = subprocess.run(
                ["python", "build_rag_db.py"], 
                capture_output=True, 
                text=True,
                cwd=Path(__file__).parent.parent
            )
            
            if result.returncode == 0:
                rag_db_status = {
                    "status": "success",
                    "output": result.stdout,
                    "timestamp": datetime.now().isoformat()
                }
                
                messages.append(AIMessage(content="RAG ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ"))
                
                return {
                    **state,
                    "rag_db_status": rag_db_status,
                    "current_step": "build_rag_db",
                    "completed_steps": state.get("completed_steps", []) + ["build_rag_db"],
                    "messages": messages
                }
            else:
                error_msg = f"RAG DB êµ¬ì¶• ì‹¤íŒ¨: {result.stderr}"
                messages.append(AIMessage(content=error_msg))
                
                return {
                    **state,
                    "errors": state.get("errors", []) + [error_msg],
                    "messages": messages
                }
                
        except Exception as e:
            error_msg = f"RAG DB êµ¬ì¶• ì¤‘ ì˜¤ë¥˜: {str(e)}"
            messages.append(AIMessage(content=error_msg))
            
            return {
                **state,
                "errors": state.get("errors", []) + [error_msg],
                "messages": messages
            }
    
    async def query_system_node(self, state: ArchitecturalWorkflowState) -> ArchitecturalWorkflowState:
        """5ë‹¨ê³„: ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ"""
        
        messages = state.get("messages", [])
        query = state.get("query", "")
        
        if not query:
            return {
                **state,
                "current_step": "query_system",
                "completed_steps": state.get("completed_steps", []) + ["query_system"],
                "messages": messages
            }
        
        messages.append(SystemMessage(content=f"ì§ˆì˜ì‘ë‹µì„ ì‹¤í–‰í•©ë‹ˆë‹¤: {query}"))
        
        try:
            # query_rag.py ì‹¤í–‰
            import subprocess
            result = subprocess.run(
                ["python", "query_rag.py", query], 
                capture_output=True, 
                text=True,
                cwd=Path(__file__).parent.parent
            )
            
            if result.returncode == 0:
                query_result = result.stdout
                messages.append(AIMessage(content=f"ì§ˆì˜ì‘ë‹µ ì™„ë£Œ:\n{query_result}"))
                
                return {
                    **state,
                    "final_results": {
                        **state.get("final_results", {}),
                        "query_result": query_result
                    },
                    "current_step": "query_system",
                    "completed_steps": state.get("completed_steps", []) + ["query_system"],
                    "messages": messages
                }
            else:
                error_msg = f"ì§ˆì˜ì‘ë‹µ ì‹¤íŒ¨: {result.stderr}"
                messages.append(AIMessage(content=error_msg))
                
                return {
                    **state,
                    "errors": state.get("errors", []) + [error_msg],
                    "messages": messages
                }
                
        except Exception as e:
            error_msg = f"ì§ˆì˜ì‘ë‹µ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            messages.append(AIMessage(content=error_msg))
            
            return {
                **state,
                "errors": state.get("errors", []) + [error_msg],
                "messages": messages
            }
    
    async def generate_report_node(self, state: ArchitecturalWorkflowState) -> ArchitecturalWorkflowState:
        """6ë‹¨ê³„: ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        
        messages = state.get("messages", [])
        messages.append(SystemMessage(content="ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."))
        
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
            report = {
                "project_name": state.get("project_name", "Unknown"),
                "execution_time": datetime.now().isoformat(),
                "completed_steps": state.get("completed_steps", []),
                "errors": state.get("errors", []),
                "extracted_texts_count": len(state.get("extracted_texts", [])),
                "metadata_results_count": len(state.get("metadata_results", [])),
                "relationships_count": len(state.get("relationships", [])),
                "rag_db_status": state.get("rag_db_status", {}),
                "query_result": state.get("final_results", {}).get("query_result", ""),
                "success": len(state.get("errors", [])) == 0
            }
            
            # ë³´ê³ ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥
            report_md = self._generate_markdown_report(report)
            report_file = Path(__file__).parent.parent / f"workflow_reports/report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            report_file.parent.mkdir(exist_ok=True)
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_md)
            
            messages.append(AIMessage(content=f"ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}"))
            
            return {
                **state,
                "final_results": {
                    **state.get("final_results", {}),
                    "report": report,
                    "report_file": str(report_file)
                },
                "current_step": "generate_report",
                "completed_steps": state.get("completed_steps", []) + ["generate_report"],
                "messages": messages
            }
            
        except Exception as e:
            error_msg = f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            messages.append(AIMessage(content=error_msg))
            
            return {
                **state,
                "errors": state.get("errors", []) + [error_msg],
                "messages": messages
            }
    
    def _generate_markdown_report(self, report: Dict[str, Any]) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±"""
        
        md_content = f"""# ê±´ì¶• ë„ë©´ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ë³´ê³ ì„œ

## í”„ë¡œì íŠ¸ ì •ë³´
- **í”„ë¡œì íŠ¸ëª…**: {report['project_name']}
- **ì‹¤í–‰ ì‹œê°„**: {report['execution_time']}
- **ì„±ê³µ ì—¬ë¶€**: {'âœ… ì„±ê³µ' if report['success'] else 'âŒ ì‹¤íŒ¨'}

## ì‹¤í–‰ ë‹¨ê³„
{chr(10).join([f"- âœ… {step}" for step in report['completed_steps']])}

## ê²°ê³¼ ìš”ì•½
- **ì¶”ì¶œëœ í…ìŠ¤íŠ¸**: {report['extracted_texts_count']}ê°œ í”„ë¡œì íŠ¸
- **ë©”íƒ€ë°ì´í„° ê²°ê³¼**: {report['metadata_results_count']}ê°œ í”„ë¡œì íŠ¸  
- **ê´€ê³„ ì¶”ë¡  ê²°ê³¼**: {report['relationships_count']}ê°œ í”„ë¡œì íŠ¸
- **RAG DB ìƒíƒœ**: {report['rag_db_status'].get('status', 'Unknown')}

## ì§ˆì˜ì‘ë‹µ ê²°ê³¼
```
{report.get('query_result', 'ì§ˆì˜ ì—†ìŒ')}
```

## ì˜¤ë¥˜ ë‚´ì—­
{chr(10).join([f"- âŒ {error}" for error in report['errors']]) if report['errors'] else 'ì˜¤ë¥˜ ì—†ìŒ'}

---
*LangGraph ê¸°ë°˜ ìë™ ìƒì„± ë³´ê³ ì„œ*
"""
        return md_content
    
    async def run_workflow(self, 
                          project_name: str,
                          pdf_files: List[str] = None,
                          query: str = None) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        
        if not HAS_LANGGRAPH:
            raise RuntimeError("LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = ArchitecturalWorkflowState(
            project_name=project_name,
            pdf_files=pdf_files or [],
            query=query,
            extracted_texts=[],
            metadata_results=[],
            relationships=[],
            rag_db_status={},
            messages=[],
            current_step="",
            completed_steps=[],
            errors=[],
            final_results={}
        )
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        config = {"configurable": {"thread_id": f"workflow_{datetime.now().timestamp()}"}}
        
        try:
            final_state = await self.app.ainvoke(initial_state, config)
            return final_state
            
        except Exception as e:
            logger.error(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                **initial_state,
                "errors": [str(e)],
                "final_results": {"error": str(e)}
            }

# CLI ì¸í„°í˜ì´ìŠ¤
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="LangGraph ê¸°ë°˜ ê±´ì¶• ë„ë©´ ë¶„ì„ ì›Œí¬í”Œë¡œìš°")
    parser.add_argument("--project", type=str, default="Default Project", help="í”„ë¡œì íŠ¸ëª…")
    parser.add_argument("--query", type=str, help="ì§ˆì˜í•  ë‚´ìš© (ì„ íƒ)")
    parser.add_argument("--llm-model", type=str, default="qwen2.5:7b", help="ì‚¬ìš©í•  LLM ëª¨ë¸")
    
    args = parser.parse_args()
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    workflow = ArchitecturalAnalysisWorkflow(llm_model=args.llm_model)
    
    print(f"ğŸš€ LangGraph ì›Œí¬í”Œë¡œìš° ì‹œì‘: {args.project}")
    
    result = await workflow.run_workflow(
        project_name=args.project,
        query=args.query
    )
    
    if result.get("final_results", {}).get("report_file"):
        print(f"ğŸ“ ë³´ê³ ì„œ ìƒì„±ë¨: {result['final_results']['report_file']}")
    
    if result.get("errors"):
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:")
        for error in result["errors"]:
            print(f"  - {error}")
    else:
        print("âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
