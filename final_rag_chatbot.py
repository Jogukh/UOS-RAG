#!/usr/bin/env python3
"""
ê±´ì¶• ë„ë©´ RAG ì±—ë´‡ - ìµœì¢… ì™„ì„± ë²„ì „
DWG íŒŒì¼ì—ì„œ ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ
"""

import sys
import os
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
import json
from datetime import datetime
import colorama
from colorama import Fore, Style, Back

# ì»¬ëŸ¬ ì¶œë ¥ ì´ˆê¸°í™”
colorama.init()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from dotenv import load_dotenv
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EnhancedRAGChatbot:
    """í–¥ìƒëœ ê±´ì¶• ë„ë©´ RAG ì±—ë´‡"""
    
    def __init__(self, collection_name: str = "test_architectural_metadata"):
        """
        Args:
            collection_name: ì‚¬ìš©í•  ChromaDB ì»¬ë ‰ì…˜ëª…
        """
        self.collection_name = collection_name
        self.vector_db = None
        self.llm_client = None
        self.conversation_history = []
        self.stats = {}
        
        print(f"{Fore.CYAN}ğŸ—ï¸ ê±´ì¶• ë„ë©´ RAG ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...{Style.RESET_ALL}")
        self._initialize_components()
    
    def _initialize_components(self):
        """RAG ì‹œìŠ¤í…œ êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”"""
        try:
            # ë²¡í„° DB ì´ˆê¸°í™”
            print(f"{Fore.YELLOW}ğŸ”§ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”©...{Style.RESET_ALL}")
            from src.metadata_vector_db import MetadataVectorDB
            self.vector_db = MetadataVectorDB(collection_name=self.collection_name)
            
            # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            print(f"{Fore.YELLOW}ğŸ¤– AI ì–¸ì–´ ëª¨ë¸ ë¡œë”©...{Style.RESET_ALL}")
            from src.llm_metadata_extractor import LLMMetadataExtractor
            self.llm_extractor = LLMMetadataExtractor()
            
            # ì‹œìŠ¤í…œ í†µê³„
            self.stats = self.vector_db.get_collection_stats()
            
            print(f"{Fore.GREEN}âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ{Style.RESET_ALL}")
            print(f"  ğŸ“Š ë²¡í„° DB: {self.stats['total_vectors']}ê°œ ë¬¸ì„œ")
            print(f"  ğŸ§  LLM: {getattr(self.llm_extractor, 'model_name', 'Ollama Gemma')}") 
            print(f"  ğŸ¯ ì»¬ë ‰ì…˜: {self.collection_name}")
            
        except Exception as e:
            print(f"{Fore.RED}âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}{Style.RESET_ALL}")
            raise
    
    def search_relevant_documents(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            results = self.vector_db.search_similar_metadata(query, top_k=top_k)
            return results
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def format_context_for_llm(self, search_results: List[Dict[str, Any]], query: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMìš© ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not search_results:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        context_parts.append(f"ì‚¬ìš©ì ì§ˆë¬¸: {query}")
        context_parts.append("\\nê²€ìƒ‰ëœ ê´€ë ¨ ê±´ì¶• ë„ë©´ ì •ë³´:")
        
        for i, result in enumerate(search_results, 1):
            metadata = result['metadata']
            similarity = result['similarity']
            
            context_parts.append(f"\\n[ë¬¸ì„œ {i}] (ê´€ë ¨ë„: {similarity:.3f})")
            context_parts.append(f"ì œëª©: {metadata.get('title', 'N/A')}")
            context_parts.append(f"ë„ë©´ ìœ í˜•: {metadata.get('drawing_type', 'N/A')}")
            context_parts.append(f"íŒŒì¼ëª…: {metadata.get('filename', 'N/A')}")
            context_parts.append(f"í”„ë¡œì íŠ¸: {metadata.get('project_name', 'N/A')}")
            
            # ë¬¸ì„œ ë‚´ìš© í¬í•¨
            if 'content' in result:
                content = result['content']
                if len(content) > 200:
                    content = content[:200] + "..."
                context_parts.append(f"ë‚´ìš©: {content}")
        
        return "\\n".join(context_parts)
    
    def generate_answer(self, query: str, context: str) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
        try:
            # RAG ì‹œìŠ¤í…œìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            rag_prompt = f"""ë‹¹ì‹ ì€ ê±´ì¶• ë„ë©´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ê±´ì¶• ë„ë©´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ê²€ìƒ‰ëœ ë„ë©´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. êµ¬ì²´ì ì¸ ë„ë©´ëª…, íŒŒì¼ëª…, ë„ë©´ ìœ í˜•ì„ ì–¸ê¸‰í•˜ì„¸ìš”
3. ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”
4. ê±´ì¶• ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë˜ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”
5. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”

{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
ì§ˆë¬¸: {query}

ë‹µë³€:"""
            
            # LangChain ChatOllamaë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
            if self.llm_extractor.llm is None:
                return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ëª¨ë¸ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            response = self.llm_extractor.llm.invoke(rag_prompt)
            answer = response.content.strip()
            
            return answer
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def chat(self, user_query: str, max_results: int = 3) -> Dict[str, Any]:
        """RAG ê¸°ë°˜ ì±—ë´‡ ëŒ€í™”"""
        try:
            # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            search_results = self.search_relevant_documents(user_query, top_k=max_results)
            
            # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self.format_context_for_llm(search_results, user_query)
            
            # 3. LLM ë‹µë³€ ìƒì„±
            answer = self.generate_answer(user_query, context)
            
            # 4. ëŒ€í™” ê¸°ë¡ ì €ì¥
            conversation_entry = {
                "timestamp": datetime.now().isoformat(),
                "query": user_query,
                "search_results_count": len(search_results),
                "answer": answer,
                "search_results": search_results
            }
            self.conversation_history.append(conversation_entry)
            
            return {
                "query": user_query,
                "answer": answer,
                "search_results": search_results,
                "search_count": len(search_results),
                "timestamp": conversation_entry["timestamp"]
            }
            
        except Exception as e:
            return {
                "query": user_query,
                "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "search_results": [],
                "search_count": 0,
                "timestamp": datetime.now().isoformat()
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        return {
            "vector_db_stats": self.stats,
            "conversation_count": len(self.conversation_history),
            "model_name": getattr(self.llm_extractor, 'model_name', 'Unknown'),
            "collection_name": self.collection_name
        }
    
    def save_conversation(self, filename: str = None):
        """ëŒ€í™” ê¸°ë¡ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"rag_conversation_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
            return filename
        except Exception as e:
            logger.error(f"ëŒ€í™” ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

def display_welcome():
    """í™˜ì˜ ë©”ì‹œì§€ ì¶œë ¥"""
    print(f"{Fore.BLUE}{Style.BRIGHT}")
    print("=" * 70)
    print("ğŸ—ï¸  ê±´ì¶• ë„ë©´ RAG ì±—ë´‡ v2.0")
    print("   DWG íŒŒì¼ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")
    print("=" * 70)
    print(f"{Style.RESET_ALL}")
    print(f"{Fore.GREEN}ğŸ’¡ ì´ ì±—ë´‡ì€ ê±´ì¶• ë„ë©´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.{Style.RESET_ALL}")
    print(f"{Fore.CYAN}ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:{Style.RESET_ALL}")
    print("   â€¢ 'help' ë˜ëŠ” 'ë„ì›€ë§' - ì‚¬ìš©ë²• ë³´ê¸°")
    print("   â€¢ 'stats' ë˜ëŠ” 'í†µê³„' - ì‹œìŠ¤í…œ ì •ë³´ ë³´ê¸°")
    print("   â€¢ 'save' ë˜ëŠ” 'ì €ì¥' - ëŒ€í™” ê¸°ë¡ ì €ì¥")
    print("   â€¢ 'clear' ë˜ëŠ” 'ì´ˆê¸°í™”' - í™”ë©´ ì§€ìš°ê¸°")
    print("   â€¢ 'quit', 'exit', 'ì¢…ë£Œ' - ì±—ë´‡ ì¢…ë£Œ")
    print()

def display_help():
    """ë„ì›€ë§ ì¶œë ¥"""
    print(f"{Fore.YELLOW}{Style.BRIGHT}ğŸ“š ì‚¬ìš©ë²• ê°€ì´ë“œ{Style.RESET_ALL}")
    print("-" * 50)
    print("ğŸ” ì§ˆë¬¸ ì˜ˆì‹œ:")
    print("   â€¢ 'ì£¼ë™ ì…ë©´ë„ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”'")
    print("   â€¢ 'ì´ í”„ë¡œì íŠ¸ì—ëŠ” ì–´ë–¤ ë„ë©´ë“¤ì´ ìˆë‚˜ìš”?'")
    print("   â€¢ 'í‰ë©´ë„ì™€ ì…ë©´ë„ì˜ ì°¨ì´ì ì€?'")
    print("   â€¢ 'ì§€í•˜ì£¼ì°¨ì¥ ê´€ë ¨ ë„ë©´ì´ ìˆë‚˜ìš”?'")
    print("   â€¢ 'ê±´ì¶• ì„¤ê³„ ë„ë©´ì˜ íŠ¹ì§•ì€?'")
    print()
    print("ğŸ’¡ íŒ:")
    print("   â€¢ êµ¬ì²´ì ì¸ ë„ë©´ëª…ì´ë‚˜ ê±´ì¶• ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("   â€¢ ì—¬ëŸ¬ ì§ˆë¬¸ì„ ì—°ì†ìœ¼ë¡œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print()

def display_stats(chatbot: EnhancedRAGChatbot):
    """ì‹œìŠ¤í…œ í†µê³„ ì¶œë ¥"""
    stats = chatbot.get_stats()
    print(f"{Fore.MAGENTA}{Style.BRIGHT}ğŸ“Š ì‹œìŠ¤í…œ í†µê³„{Style.RESET_ALL}")
    print("-" * 50)
    print(f"ğŸ—ƒï¸  ë²¡í„° DB ë¬¸ì„œ ìˆ˜: {stats['vector_db_stats']['total_vectors']}ê°œ")
    print(f"ğŸ¤– AI ëª¨ë¸: {stats['model_name']}")
    print(f"ğŸ’¬ ëŒ€í™” ìˆ˜: {stats['conversation_count']}íšŒ")
    print(f"ğŸ¯ ì»¬ë ‰ì…˜: {stats['collection_name']}")
    print()

def display_search_results(results: List[Dict[str, Any]]):
    """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ"""
    if not results:
        print(f"{Fore.YELLOW}âš ï¸  ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.{Style.RESET_ALL}")
        return
    
    print(f"{Fore.CYAN}ğŸ“‹ ì°¸ì¡°ëœ ë¬¸ì„œ ({len(results)}ê°œ):{Style.RESET_ALL}")
    for i, result in enumerate(results, 1):
        metadata = result['metadata']
        similarity = result['similarity']
        print(f"  {i}. {Fore.WHITE}{metadata.get('title', 'N/A')}{Style.RESET_ALL} "
              f"({Fore.GREEN}ê´€ë ¨ë„: {similarity:.3f}{Style.RESET_ALL})")

def interactive_chat():
    """í–¥ìƒëœ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤"""
    display_welcome()
    
    try:
        # RAG ì±—ë´‡ ì´ˆê¸°í™”
        chatbot = EnhancedRAGChatbot()
        print(f"{Fore.GREEN}âœ… ì±—ë´‡ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!{Style.RESET_ALL}")
        print()
        
        while True:
            # ì‚¬ìš©ì ì…ë ¥
            user_input = input(f"{Fore.BLUE}ğŸ™‹ ì§ˆë¬¸: {Style.RESET_ALL}").strip()
            
            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print(f"\\n{Fore.GREEN}ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!{Style.RESET_ALL}")
                break
            
            elif user_input.lower() in ['help', 'ë„ì›€ë§', 'h']:
                display_help()
                continue
            
            elif user_input.lower() in ['stats', 'í†µê³„']:
                display_stats(chatbot)
                continue
            
            elif user_input.lower() in ['save', 'ì €ì¥']:
                filename = chatbot.save_conversation()
                if filename:
                    print(f"\\n{Fore.GREEN}ğŸ’¾ ëŒ€í™” ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}{Style.RESET_ALL}\\n")
                continue
            
            elif user_input.lower() in ['clear', 'ì´ˆê¸°í™”']:
                os.system('clear' if os.name == 'posix' else 'cls')
                display_welcome()
                continue
            
            # ë¹ˆ ì…ë ¥ ì²˜ë¦¬
            if not user_input:
                print(f"{Fore.YELLOW}ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.{Style.RESET_ALL}")
                continue
            
            # RAG ì‘ë‹µ ìƒì„±
            print(f"\\n{Fore.YELLOW}ğŸ” ê²€ìƒ‰ ì¤‘...{Style.RESET_ALL}")
            response = chatbot.chat(user_input)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\\n{Fore.GREEN}{Style.BRIGHT}ğŸ¤– ë‹µë³€:{Style.RESET_ALL}")
            print(f"{response['answer']}")
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            print()
            display_search_results(response['search_results'])
            print("-" * 70)
    
    except KeyboardInterrupt:
        print(f"\\n\\n{Fore.YELLOW}ğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.{Style.RESET_ALL}")
    except Exception as e:
        print(f"\\n{Fore.RED}âŒ ì±—ë´‡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}{Style.RESET_ALL}")

def quick_demo():
    """ë¹ ë¥¸ ë°ëª¨ ì‹¤í–‰"""
    demo_queries = [
        "ì£¼ë™ ì…ë©´ë„ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
        "ì´ í”„ë¡œì íŠ¸ì—ëŠ” ì–´ë–¤ ë„ë©´ë“¤ì´ ìˆë‚˜ìš”?",
        "í‰ë©´ë„ì™€ ì…ë©´ë„ì˜ ì°¨ì´ì ì€?"
    ]
    
    print(f"{Fore.MAGENTA}{Style.BRIGHT}ğŸ¬ RAG ì±—ë´‡ ë°ëª¨{Style.RESET_ALL}")
    print("=" * 50)
    
    try:
        chatbot = EnhancedRAGChatbot()
        
        for i, query in enumerate(demo_queries, 1):
            print(f"\\n{Fore.CYAN}[ë°ëª¨ {i}] {query}{Style.RESET_ALL}")
            print("-" * 40)
            
            response = chatbot.chat(query)
            
            # ë‹µë³€ ìš”ì•½ ì¶œë ¥ (ì²˜ìŒ 150ì)
            answer_preview = response['answer'][:150] + "..." if len(response['answer']) > 150 else response['answer']
            print(f"{Fore.GREEN}ë‹µë³€:{Style.RESET_ALL} {answer_preview}")
            
            display_search_results(response['search_results'])
        
        print(f"\\n{Fore.GREEN}âœ… ë°ëª¨ ì™„ë£Œ{Style.RESET_ALL}")
        
        # ëŒ€í™”í˜• ëª¨ë“œë¡œ ì „í™˜ ì œì•ˆ
        if input(f"\\n{Fore.YELLOW}ëŒ€í™”í˜• ëª¨ë“œë¡œ ì „í™˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): {Style.RESET_ALL}").lower() == 'y':
            print()
            interactive_chat()
        
    except Exception as e:
        print(f"{Fore.RED}âŒ ë°ëª¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}{Style.RESET_ALL}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ê±´ì¶• ë„ë©´ RAG ì±—ë´‡ v2.0",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python final_rag_chatbot.py                    # ëŒ€í™”í˜• ëª¨ë“œ
  python final_rag_chatbot.py --demo             # ë°ëª¨ ì‹¤í–‰
  python final_rag_chatbot.py --mode interactive # ëŒ€í™”í˜• ëª¨ë“œ
        """
    )
    
    parser.add_argument("--mode", choices=["interactive", "demo"], default="interactive",
                       help="ì‹¤í–‰ ëª¨ë“œ ì„ íƒ")
    parser.add_argument("--demo", action="store_true", 
                       help="ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    if args.demo or args.mode == "demo":
        quick_demo()
    else:
        interactive_chat()

if __name__ == "__main__":
    main()
