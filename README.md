# VLM ê¸°ë°˜ ê±´ì¶• ë„ë©´ ë¶„ì„ ì‹œìŠ¤í…œ (vLLM ìµœì í™”)

AutoCAD PDF ë„ë©´ì—ì„œ ë²¡í„° ê·¸ë˜í”½ì„ ì§ì ‘ ë¶„ì„í•˜ì—¬ ê±´ì¶• ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³ ì„±ëŠ¥ AI ì‹œìŠ¤í…œ

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- **ë²¡í„° ê¸°ë°˜ ë„ë©´ ë¶„ì„**: PyMuPDFë¥¼ ì´ìš©í•œ ì§ì ‘ì ì¸ ë²¡í„° ë°ì´í„° ì¶”ì¶œ
- **ê³ ì„±ëŠ¥ VLM ì¶”ë¡ **: vLLMì„ í™œìš©í•œ ìµœì í™”ëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ ì²˜ë¦¬
- **Qwen2.5-VL í†µí•©**: ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ í†µí•œ ì •í™•í•œ íŒ¨í„´ ë¶„ì„
- **LangGraph ì›Œí¬í”Œë¡œìš°**: ì²´ê³„ì ì¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬
- **ê±´ì¶• ìš”ì†Œ ê²€ì¶œ**: ë²½, ë¬¸, ì°½ë¬¸, ê³µê°„ ë“± ìë™ ì‹ë³„
- **ì‹ ë¢°ë„ ê¸°ë°˜ í†µí•©**: ë‹¤ì¤‘ ë¶„ì„ ê²°ê³¼ì˜ ì§€ëŠ¥ì  ê²°í•©
- **ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›**: ë‹¤ì¤‘ ë„ë©´ ë™ì‹œ ë¶„ì„
- **ì„±ëŠ¥ ìµœì í™”**: GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì‚¬ìš© ë° ì²˜ë¦¬ëŸ‰ í–¥ìƒ

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
AutoCAD PDF â†’ ë²¡í„° ë°ì´í„° ì¶”ì¶œ â†’ íŒ¨í„´ ë¶„ì„ â†’ êµ¬ì¡°í™”ëœ ê±´ì¶• ë°ì´í„°
              â†“                    â†‘
              ì´ë¯¸ì§€ ë³€í™˜ â†’ vLLM ì¶”ë¡  â†—
                          (Qwen2.5-VL)
```

## âš¡ vLLM ìµœì í™” íŠ¹ì§•

- **ê³ ì† ì¶”ë¡ **: transformers ëŒ€ë¹„ ìµœëŒ€ 5-10ë°° ì†ë„ í–¥ìƒ
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: PagedAttentionìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ìµœì  ì‚¬ìš©
- **ë°°ì¹˜ ì²˜ë¦¬**: ë™ì‹œ ë‹¤ì¤‘ ìš”ì²­ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”
- **ìë™ ìŠ¤ì¼€ì¼ë§**: GPU ë¦¬ì†ŒìŠ¤ì— ë”°ë¥¸ ìë™ ì„¤ì • ìµœì í™”
- **Fallback ì§€ì›**: vLLM ë¶ˆê°€ ì‹œ transformers ìë™ ì „í™˜

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# ì˜ì¡´ì„± ì„¤ì¹˜ (vLLM í¬í•¨)
pip install -r requirements.txt

# vLLM ìˆ˜ë™ ì„¤ì¹˜ (ê¶Œì¥)
pip install vllm>=0.7.2
```

### 2. vLLM ì„¤ì • ìµœì í™”

```bash
# ì‹œìŠ¤í…œì— ë§ëŠ” vLLM ì„¤ì • ìë™ ìƒì„±
python src/vllm_config.py

# ìƒì„±ëœ ì„¤ì • íŒŒì¼ë“¤:
# - configs/vllm_auto.json (ìë™ ê°ì§€)
# - configs/vllm_throughput.json (ì²˜ë¦¬ëŸ‰ ìµœì í™”)
# - configs/vllm_latency.json (ì§€ì—°ì‹œê°„ ìµœì í™”)
# - configs/vllm_memory.json (ë©”ëª¨ë¦¬ ìµœì í™”)
```

### 3. ê¸°ë³¸ ì‚¬ìš©ë²•

#### vLLM ë¶„ì„ê¸° ì‚¬ìš©
```python
from src.vllm_analyzer import VLLMAnalyzer

# vLLM ë¶„ì„ê¸° ì´ˆê¸°í™” (ìë™ ìµœì í™”)
analyzer = VLLMAnalyzer(
    model_name="Qwen/Qwen2.5-VL-7B-Instruct",
    tensor_parallel_size=1,
    gpu_memory_utilization=0.8
)

# ëª¨ë¸ ë¡œë“œ
analyzer.load_model()

# ì´ë¯¸ì§€ ë¶„ì„
result = workflow.analyze_page("uploads/architectural-plan.pdf", page_number=0)

# ê²°ê³¼ í™•ì¸
print(f"ë²½: {result['final_analysis']['summary']['total_walls']}ê°œ")
print(f"ë¬¸: {result['final_analysis']['summary']['total_doors']}ê°œ")
print(f"ì°½ë¬¸: {result['final_analysis']['summary']['total_windows']}ê°œ")
print(f"ê³µê°„: {result['final_analysis']['summary']['total_spaces']}ê°œ")
```

#### ë°°ì¹˜ ì²˜ë¦¬ (ê³ ê¸‰)
```python
import asyncio
from src.vllm_analyzer import VLLMAnalyzer

# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ë¶„ì„
analyzer = VLLMAnalyzer()
analyzer.load_model()

# ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
async def batch_analysis():
    results = await analyzer.analyze_batch(
        images=image_list,
        analysis_types=["element_detection"] * len(image_list)
    )
    return results

# ì‹¤í–‰
results = asyncio.run(batch_analysis())
```

### 4. í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬

```bash
# í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_vllm_integration.py

# ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
python src/vllm_analyzer.py  # ë‹¨ì¼ í…ŒìŠ¤íŠ¸
python src/qwen_vlm_analyzer_fixed.py  # ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
VLM/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ architectural_vector_analyzer.py     # ë²¡í„° ê¸°ë°˜ ê±´ì¶• ë¶„ì„ê¸°
â”‚   â”œâ”€â”€ qwen_vlm_analyzer_fixed.py          # VLM ë¶„ì„ê¸° (vLLM ì§€ì›)
â”‚   â”œâ”€â”€ vllm_analyzer.py                    # ìˆœìˆ˜ vLLM ë¶„ì„ê¸°
â”‚   â”œâ”€â”€ vllm_config.py                      # vLLM ì„¤ì • ë° ìµœì í™”
â”‚   â”œâ”€â”€ vlm_pattern_workflow_fixed.py       # LangGraph í†µí•© ì›Œí¬í”Œë¡œìš°
â”‚   â””â”€â”€ vlm_enhanced_pattern_analyzer.py    # VLM í–¥ìƒ íŒ¨í„´ ë¶„ì„ê¸°
â”œâ”€â”€ configs/                                # vLLM ì„¤ì • íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ vllm_auto.json                     # ìë™ ê°ì§€ ì„¤ì •
â”‚   â”œâ”€â”€ vllm_throughput.json               # ì²˜ë¦¬ëŸ‰ ìµœì í™”
â”‚   â”œâ”€â”€ vllm_latency.json                  # ì§€ì—°ì‹œê°„ ìµœì í™”
â”‚   â””â”€â”€ vllm_memory.json                   # ë©”ëª¨ë¦¬ ìµœì í™”
â”œâ”€â”€ models/                                 # AI ëª¨ë¸ë“¤
â”œâ”€â”€ uploads/                               # í…ŒìŠ¤íŠ¸ PDF íŒŒì¼ë“¤
â”œâ”€â”€ vector_db/                            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
â”œâ”€â”€ test_vllm_integration.py             # vLLM í†µí•© í…ŒìŠ¤íŠ¸
â””â”€â”€ requirements.txt                      # ì˜ì¡´ì„± ëª©ë¡
```

## ğŸ”§ ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### 1. ë²¡í„° ë¶„ì„ê¸° (`architectural_vector_analyzer.py`)
- PyMuPDFë¥¼ ì´ìš©í•œ ë²¡í„° ë°ì´í„° ì§ì ‘ ì¶”ì¶œ
- ê±´ì¶• ìš”ì†Œë³„ íŒ¨í„´ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
- ê¸°í•˜í•™ì  ë¶„ì„ì„ í†µí•œ êµ¬ì¡° ìš”ì†Œ ì‹ë³„

### 2. vLLM ë¶„ì„ê¸° (`vllm_analyzer.py`)
- ìˆœìˆ˜ vLLM ê¸°ë°˜ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ 
- ìë™ GPU ë¦¬ì†ŒìŠ¤ ìµœì í™”
- ë°°ì¹˜ ì²˜ë¦¬ ë° ë¹„ë™ê¸° ë¶„ì„ ì§€ì›
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬

### 3. í•˜ì´ë¸Œë¦¬ë“œ VLM ë¶„ì„ê¸° (`qwen_vlm_analyzer_fixed.py`)
- vLLM ìš°ì„ , transformers fallback ì§€ì›
- ìë™ ëª¨ë¸ ë¡œë”© ë° ì„¤ì • ìµœì í™”
- ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì •ë¦¬ ê¸°ëŠ¥

### 4. ì„¤ì • ê´€ë¦¬ì (`vllm_config.py`)
- í•˜ë“œì›¨ì–´ë³„ ìë™ ì„¤ì • ê°ì§€
- ì„±ëŠ¥ ìµœì í™” í”„ë¡œíŒŒì¼ ì œê³µ
- ëŸ°íƒ€ì„ ì„¤ì • ì¡°ì • ë„êµ¬

### 5. í†µí•© ì›Œí¬í”Œë¡œìš° (`vlm_pattern_workflow_fixed.py`)
- LangGraph ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬
- vLLM í†µí•© ì§€ì›
- ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•œ ì„±ëŠ¥ ìµœì í™”
- ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì‹ ë¢°ë„ ê²€ì¦

## âš¡ ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ë©”ëª¨ë¦¬ ì œí•œ í™˜ê²½
analyzer = VLLMAnalyzer(
    model_name="Qwen/Qwen2.5-VL-7B-Instruct",
    gpu_memory_utilization=0.7,  # ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
    max_model_len=4096           # ì§§ì€ ì»¨í…ìŠ¤íŠ¸
)

# ê³ ë©”ëª¨ë¦¬ í™˜ê²½
analyzer = VLLMAnalyzer(
    model_name="Qwen/Qwen2.5-VL-72B-Instruct",
    gpu_memory_utilization=0.95,  # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
    tensor_parallel_size=4        # ë‹¤ì¤‘ GPU ì‚¬ìš©
)
```

### ì²˜ë¦¬ëŸ‰ vs ì§€ì—°ì‹œê°„ ìµœì í™”
```python
# ì²˜ë¦¬ëŸ‰ ìš°ì„  (ë°°ì¹˜ ì²˜ë¦¬)
from src.vllm_config import VLLMOptimizer
config = VLLMOptimizer.optimize_for_throughput(base_config)

# ì§€ì—°ì‹œê°„ ìš°ì„  (ì‹¤ì‹œê°„ ì²˜ë¦¬)
config = VLLMOptimizer.optimize_for_latency(base_config)
```

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•

### vLLM vs transformers ë¹„êµ
| íŠ¹ì§• | vLLM | transformers |
|------|------|--------------|
| **ì¶”ë¡  ì†ë„** | 5-10ë°° ë¹ ë¦„ | ê¸°ì¤€ ì†ë„ |
| **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±** | PagedAttention | í‘œì¤€ ì–´í…ì…˜ |
| **ë°°ì¹˜ ì²˜ë¦¬** | ë™ì  ë°°ì¹˜ | ì •ì  ë°°ì¹˜ |
| **GPU í™œìš©ë¥ ** | 90%+ | 60-70% |
| **ë™ì‹œ ìš”ì²­** | ìˆ˜ì‹­ê°œ | ìˆ˜ê°œ |

### ê¶Œì¥ í•˜ë“œì›¨ì–´ ì‚¬ì–‘
- **ìµœì†Œ**: NVIDIA RTX 3080 (10GB VRAM)
- **ê¶Œì¥**: NVIDIA RTX 4090 (24GB VRAM)  
- **ìµœì **: NVIDIA A100 (40/80GB VRAM)
- **ë‹¤ì¤‘ GPU**: 2-4x RTX 4090 ë˜ëŠ” A100

## ğŸš¨ ë¬¸ì œ í•´ê²°

### vLLM ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# ì˜¬ë°”ë¥¸ CUDA ë²„ì „ìœ¼ë¡œ PyTorch ì¬ì„¤ì¹˜
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# vLLM ì¬ì„¤ì¹˜
pip install vllm --no-cache-dir
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
```python
# ì„¤ì • ì¡°ì •
analyzer = VLLMAnalyzer(
    gpu_memory_utilization=0.6,  # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê°ì†Œ
    max_model_len=2048,          # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê°ì†Œ
    enable_chunked_prefill=True  # ì²­í¬ ì²˜ë¦¬ í™œì„±í™”
)
```

### Fallback ëª¨ë“œ ì‚¬ìš©
```python
# vLLM ì‹¤íŒ¨ ì‹œ ìë™ fallback
analyzer = QwenVLMAnalyzer(use_vllm=True)  # vLLM ì‹œë„ í›„ transformersë¡œ fallback
```

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•

- **ì •í™•ë„**: ë²¡í„° + VLM í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ìœ¼ë¡œ ë†’ì€ ì •í™•ë„
- **ì†ë„**: ë³‘ë ¬ ì²˜ë¦¬ êµ¬ì¡°ë¡œ ë¹ ë¥¸ ë¶„ì„ ì‹œê°„
- **í™•ì¥ì„±**: LangGraph ê¸°ë°˜ ëª¨ë“ˆì‹ ì„¤ê³„
- **ì‹ ë¢°ì„±**: ë‹¤ì¤‘ ê²€ì¦ ë° ì˜¤ë¥˜ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

## ğŸ“ ê¸°ìˆ  ìŠ¤íƒ

- **AI ëª¨ë¸**: Qwen2.5-VL (Vision-Language Model)
- **ì›Œí¬í”Œë¡œìš°**: LangChain + LangGraph
- **ë²¡í„° ì²˜ë¦¬**: PyMuPDF + Shapely
- **ì»´í“¨íŒ…**: PyTorch + CUDA

## ğŸ“ˆ ê°œë°œ í˜„í™©

- âœ… í•µì‹¬ ë¶„ì„ ì—”ì§„ ì™„ì„±
- âœ… LangGraph ì›Œí¬í”Œë¡œìš° í†µí•©
- âœ… VLM ëª¨ë¸ ìµœì í™”
- ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘
- ğŸ“‹ ì‹¤ì‹œê°„ API ê°œë°œ ì˜ˆì •

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. ì´ìŠˆ ë“±ë¡
2. ê¸°ëŠ¥ ê°œë°œ
3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
4. í’€ ë¦¬í€˜ìŠ¤íŠ¸ ì œì¶œ

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ“ ì—°ë½ì²˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ë“±ë¡í•´ ì£¼ì„¸ìš”.

---

**ìµœê·¼ ì—…ë°ì´íŠ¸**: 2025ë…„ 6ì›” 11ì¼  
**ë²„ì „**: v1.0 (ë² íƒ€)  
**ìƒíƒœ**: í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ
