# VLM ê¸°ë°˜ ê±´ì¶• ë„ë©´ ë¶„ì„ ì‹œìŠ¤í…œ (vLLM ìµœì í™”)

AutoCAD PDF ë„ë©´ì—ì„œ ë²¡í„° ê·¸ë˜í”½ì„ ì§ì ‘ ë¶„ì„í•˜ì—¬ ê±´ì¶• ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³ ì„±ëŠ¥ AI ì‹œìŠ¤í…œ

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- **ë²¡í„° ê¸°ë°˜ ë„ë©´ ë¶„ì„**: PyMuPDFë¥¼ ì´ìš©í•œ ì§ì ‘ì ì¸ ë²¡í„° ë°ì´í„° ì¶”ì¶œ
- **ê³ ì„±ëŠ¥ VLM ì¶”ë¡ **: vLLMì„ í™œìš©í•œ ìµœì í™”ëœ ë¹„ì „-ì–¸ì–´ ëª¨ë¸ ì²˜ë¦¬
- **Qwen2.5-VL í†µí•©**: ìµœì‹  ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ í†µí•œ ì •í™•í•œ íŒ¨í„´ ë¶„ì„
- **LangGraph ì›Œí¬í”Œë¡œìš°**: ì²´ê³„ì ì¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬
- **ê±´ì¶• ìš”ì†Œ ê²€ì¶œ**: ë²½, ë¬¸, ì°½ë¬¸, ê³µê°„ ë“± ìë™ ì‹ë³„
- **ì‹ ë¢°ë„ ê¸°ë°˜ í†µí•©**: ë‹¤ì¤‘ ë¶„ì„ ê²°ê³¼ì˜ ì§€ëŠ¥ì  ê²°í•©
- **ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›**: ë‹¤ì¤‘ ë„ë©´ ë™ì‹œ ë¶„ì„
- **ì„±ëŠ¥ ìµœì í™”**: GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì‚¬ìš© ë° ì²˜ë¦¬ëŸ‰ í–¥ìƒ

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
AutoCAD PDF â†’ ë²¡í„° ë°ì´í„° ì¶”ì¶œ â†’ íŒ¨í„´ ë¶„ì„ â†’ êµ¬ì¡°í™”ëœ ê±´ì¶• ë°ì´í„°
              â†“                    â†‘
              ì´ë¯¸ì§€ ë³€í™˜ â†’ vLLM ì¶”ë¡  â†—
                          (Qwen2.5-VL)
```

## âš¡ vLLM ìµœì í™” íŠ¹ì§•

- **ê³ ì† ì¶”ë¡ **: transformers ëŒ€ë¹„ ìµœëŒ€ 5-10ë°° ì†ë„ í–¥ìƒ
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: PagedAttentionìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ìµœì  ì‚¬ìš©
- **ë°°ì¹˜ ì²˜ë¦¬**: ë™ì‹œ ë‹¤ì¤‘ ìš”ì²­ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”
- **ìë™ ìŠ¤ì¼€ì¼ë§**: GPU ë¦¬ì†ŒìŠ¤ì— ë”°ë¥¸ ìë™ ì„¤ì • ìµœì í™”
- **Fallback ì§€ì›**: vLLM ë¶ˆê°€ ì‹œ transformers ìë™ ì „í™˜

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# ì˜ì¡´ì„± ì„¤ì¹˜ (vLLM í¬í•¨)
pip install -r requirements.txt

# vLLM ìˆ˜ë™ ì„¤ì¹˜ (ê¶Œì¥)
pip install vllm>=0.7.2
```

### 2. vLLM ì„¤ì • ìµœì í™”

```bash
# ì‹œìŠ¤í…œì— ë§ëŠ” vLLM ì„¤ì • ìë™ ìƒì„±
python src/vllm_config.py

# ìƒì„±ëœ ì„¤ì • íŒŒì¼ë“¤:
# - configs/vllm_auto.json (ìë™ ê°ì§€)
# - configs/vllm_throughput.json (ì²˜ë¦¬ëŸ‰ ìµœì í™”)
# - configs/vllm_latency.json (ì§€ì—°ì‹œê°„ ìµœì í™”)
# - configs/vllm_memory.json (ë©”ëª¨ë¦¬ ìµœì í™”)
```

### 3. LangSmith ì¶”ì  ì„¤ì • (ì„ íƒì‚¬í•­)

```bash
# 1. LangSmith API í‚¤ ë°œê¸‰
# https://smith.langchain.com/settings ì—ì„œ API í‚¤ ìƒì„±

# 2. .env íŒŒì¼ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì—ì„œ ë‹¤ìŒ ì„¤ì •:
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=your_api_key_here
LANGSMITH_PROJECT=VLM-Architecture-Analysis

# 3. LangSmith í†µí•© í…ŒìŠ¤íŠ¸
python test_langsmith_integration.py

# 4. ì¶”ì  ê²°ê³¼ í™•ì¸
# https://smith.langchain.com/projects/p/VLM-Architecture-Analysis
```

#### LangSmith ì¶”ì  í˜œíƒ
- ğŸ” **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ëª¨ë“  LLM í˜¸ì¶œê³¼ ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ì¶”ì 
- ğŸ“Š **ì„±ëŠ¥ ë¶„ì„**: ì‘ë‹µ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰, ë¹„ìš© ë¶„ì„
- ğŸ› **ë””ë²„ê¹… ì§€ì›**: ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
- ğŸ“ˆ **ê°œì„  ì§€í‘œ**: ëª¨ë¸ ì„±ëŠ¥ê³¼ ì •í™•ë„ ì¶”ì´ ëª¨ë‹ˆí„°ë§

### 4. vLLM-LangChain OpenAI API ì—°ë™

ì´ í”„ë¡œì íŠ¸ëŠ” vLLM ì„œë²„ë¥¼ OpenAI API í˜•íƒœë¡œ ì‹¤í–‰í•˜ì—¬ LangChainê³¼ ì—°ë™í•©ë‹ˆë‹¤.

#### vLLM ì„œë²„ ì‹œì‘
```bash
# 1. vLLM ì„œë²„ ì‹œì‘ (ë³„ë„ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰)
# Option A: Gemma-3 12B GGUF (ê¶Œì¥ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
./start_vllm_gemma.sh

# Option B: ìˆ˜ë™ìœ¼ë¡œ Gemma ì‹œì‘
python -m vllm.entrypoints.openai.api_server \
    --model google/gemma-3-12b-it-qat-q4_0-gguf \
    --host 0.0.0.0 \
    --port 8000 \
    --gpu-memory-utilization 0.6 \
    --max-model-len 8192

# Option C: ë‹¤ë¥¸ ëª¨ë¸ (ë” í° GPU ë©”ëª¨ë¦¬ í•„ìš”)
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen3-Reranker-4B \
    --host 0.0.0.0 \
    --port 8000 \
    --gpu-memory-utilization 0.8 \
    --max-model-len 8192

# 2. ì„œë²„ ìƒíƒœ í™•ì¸
curl http://localhost:8000/v1/models
```

#### ì§€ì›ë˜ëŠ” ëª¨ë¸
- **google/gemma-3-12b-it-qat-q4_0-gguf** (ê¶Œì¥): 4-bit ì–‘ìí™”, 8GB GPUì— ìµœì í™”
- **hyokwan/llama31_common**: Llama 3.1 ê¸°ë°˜ ëª¨ë¸
- **Qwen/Qwen3-Reranker-4B**: ë¦¬ë­í‚¹ ì „ìš© ëª¨ë¸ (ë” í° ë©”ëª¨ë¦¬ í•„ìš”)

#### LangChain ì—°ë™ ì‚¬ìš©
```python
from src.llm_metadata_extractor import LLMMetadataExtractor
from src.llm_relationship_inferencer import LLMDrawingRelationshipInferencer

# ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸° (ìë™ìœ¼ë¡œ vLLM ì„œë²„ ì—°ê²°)
extractor = LLMMetadataExtractor()

# ê±´ì¶• ë„ë©´ í…ìŠ¤íŠ¸ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
sample_text = """
ë„ë©´ë²ˆí˜¸: A01-001
ë„ë©´ëª…: 1ì¸µ í‰ë©´ë„
ì¶•ì²™: 1/100
ê±°ì‹¤: 20.5ã¡
ì£¼ë°©: 12.3ã¡
"""

metadata = extractor.extract_metadata_from_text(
    sample_text, 
    "building_plan.pdf", 
    1
)

print(f"ë„ë©´ë²ˆí˜¸: {metadata['drawing_number']}")
print(f"ë„ë©´ì œëª©: {metadata['drawing_title']}")
```

#### ì—°ë™ í…ŒìŠ¤íŠ¸
```bash
# vLLM-LangChain ì—°ë™ í…ŒìŠ¤íŠ¸
python test_vllm_langchain_integration.py
```

### 5. ê¸°ë³¸ ì‚¬ìš©ë²•

#### vLLM ë¶„ì„ê¸° ì‚¬ìš© (Legacy)
```python
from src.vllm_analyzer import VLLMAnalyzer

# vLLM ë¶„ì„ê¸° ì´ˆê¸°í™” (ìë™ ìµœì í™”)
analyzer = VLLMAnalyzer(
    model_name="Qwen/Qwen2.5-VL-7B-Instruct",
    tensor_parallel_size=1,
    gpu_memory_utilization=0.8
)

# ëª¨ë¸ ë¡œë“œ
analyzer.load_model()

# ì´ë¯¸ì§€ ë¶„ì„
result = workflow.analyze_page("uploads/architectural-plan.pdf", page_number=0)

# ê²°ê³¼ í™•ì¸
print(f"ë²½: {result['final_analysis']['summary']['total_walls']}ê°œ")
print(f"ë¬¸: {result['final_analysis']['summary']['total_doors']}ê°œ")
print(f"ì°½ë¬¸: {result['final_analysis']['summary']['total_windows']}ê°œ")
print(f"ê³µê°„: {result['final_analysis']['summary']['total_spaces']}ê°œ")
```

#### ë°°ì¹˜ ì²˜ë¦¬ (ê³ ê¸‰)
```python
import asyncio
from src.vllm_analyzer import VLLMAnalyzer

# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ë¶„ì„
analyzer = VLLMAnalyzer()
analyzer.load_model()

# ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
async def batch_analysis():
    results = await analyzer.analyze_batch(
        images=image_list,
        analysis_types=["element_detection"] * len(image_list)
    )
    return results

# ì‹¤í–‰
results = asyncio.run(batch_analysis())
```

### 6. í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬

```bash
# í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_vllm_integration.py

# ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
python src/vllm_analyzer.py  # ë‹¨ì¼ í…ŒìŠ¤íŠ¸
python src/qwen_vlm_analyzer_fixed.py  # ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
VLM/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ architectural_vector_analyzer.py     # ë²¡í„° ê¸°ë°˜ ê±´ì¶• ë¶„ì„ê¸°
â”‚   â”œâ”€â”€ qwen_vlm_analyzer_fixed.py          # VLM ë¶„ì„ê¸° (vLLM ì§€ì›)
â”‚   â”œâ”€â”€ vllm_analyzer.py                    # ìˆœìˆ˜ vLLM ë¶„ì„ê¸°
â”‚   â”œâ”€â”€ vllm_config.py                      # vLLM ì„¤ì • ë° ìµœì í™”
â”‚   â”œâ”€â”€ vlm_pattern_workflow_fixed.py       # LangGraph í†µí•© ì›Œí¬í”Œë¡œìš°
â”‚   â””â”€â”€ vlm_enhanced_pattern_analyzer.py    # VLM í–¥ìƒ íŒ¨í„´ ë¶„ì„ê¸°
â”œâ”€â”€ configs/                                # vLLM ì„¤ì • íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ vllm_auto.json                     # ìë™ ê°ì§€ ì„¤ì •
â”‚   â”œâ”€â”€ vllm_throughput.json               # ì²˜ë¦¬ëŸ‰ ìµœì í™”
â”‚   â”œâ”€â”€ vllm_latency.json                  # ì§€ì—°ì‹œê°„ ìµœì í™”
â”‚   â””â”€â”€ vllm_memory.json                   # ë©”ëª¨ë¦¬ ìµœì í™”
â”œâ”€â”€ models/                                 # AI ëª¨ë¸ë“¤
â”œâ”€â”€ uploads/                               # í…ŒìŠ¤íŠ¸ PDF íŒŒì¼ë“¤
â”œâ”€â”€ vector_db/                            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
â”œâ”€â”€ test_vllm_integration.py             # vLLM í†µí•© í…ŒìŠ¤íŠ¸
â””â”€â”€ requirements.txt                      # ì˜ì¡´ì„± ëª©ë¡
```

## ğŸ”§ ì£¼ìš” êµ¬ì„± ìš”ì†Œ

### 1. ë²¡í„° ë¶„ì„ê¸° (`architectural_vector_analyzer.py`)
- PyMuPDFë¥¼ ì´ìš©í•œ ë²¡í„° ë°ì´í„° ì§ì ‘ ì¶”ì¶œ
- ê±´ì¶• ìš”ì†Œë³„ íŒ¨í„´ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
- ê¸°í•˜í•™ì  ë¶„ì„ì„ í†µí•œ êµ¬ì¡° ìš”ì†Œ ì‹ë³„

### 2. vLLM ë¶„ì„ê¸° (`vllm_analyzer.py`)
- ìˆœìˆ˜ vLLM ê¸°ë°˜ ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ 
- ìë™ GPU ë¦¬ì†ŒìŠ¤ ìµœì í™”
- ë°°ì¹˜ ì²˜ë¦¬ ë° ë¹„ë™ê¸° ë¶„ì„ ì§€ì›
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬

### 3. í•˜ì´ë¸Œë¦¬ë“œ VLM ë¶„ì„ê¸° (`qwen_vlm_analyzer_fixed.py`)
- vLLM ìš°ì„ , transformers fallback ì§€ì›
- ìë™ ëª¨ë¸ ë¡œë”© ë° ì„¤ì • ìµœì í™”
- ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì •ë¦¬ ê¸°ëŠ¥

### 4. ì„¤ì • ê´€ë¦¬ì (`vllm_config.py`)
- í•˜ë“œì›¨ì–´ë³„ ìë™ ì„¤ì • ê°ì§€
- ì„±ëŠ¥ ìµœì í™” í”„ë¡œíŒŒì¼ ì œê³µ
- ëŸ°íƒ€ì„ ì„¤ì • ì¡°ì • ë„êµ¬

### 5. í†µí•© ì›Œí¬í”Œë¡œìš° (`vlm_pattern_workflow_fixed.py`)
- LangGraph ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬
- vLLM í†µí•© ì§€ì›
- ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•œ ì„±ëŠ¥ ìµœì í™”
- ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì‹ ë¢°ë„ ê²€ì¦

## âš¡ ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ë©”ëª¨ë¦¬ ì œí•œ í™˜ê²½
analyzer = VLLMAnalyzer(
    model_name="Qwen/Qwen2.5-VL-7B-Instruct",
    gpu_memory_utilization=0.7,  # ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
    max_model_len=4096           # ì§§ì€ ì»¨í…ìŠ¤íŠ¸
)

# ê³ ë©”ëª¨ë¦¬ í™˜ê²½
analyzer = VLLMAnalyzer(
    model_name="Qwen/Qwen2.5-VL-72B-Instruct",
    gpu_memory_utilization=0.95,  # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
    tensor_parallel_size=4        # ë‹¤ì¤‘ GPU ì‚¬ìš©
)
```

### ì²˜ë¦¬ëŸ‰ vs ì§€ì—°ì‹œê°„ ìµœì í™”
```python
# ì²˜ë¦¬ëŸ‰ ìš°ì„  (ë°°ì¹˜ ì²˜ë¦¬)
from src.vllm_config import VLLMOptimizer
config = VLLMOptimizer.optimize_for_throughput(base_config)

# ì§€ì—°ì‹œê°„ ìš°ì„  (ì‹¤ì‹œê°„ ì²˜ë¦¬)
config = VLLMOptimizer.optimize_for_latency(base_config)
```

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•

### vLLM vs transformers ë¹„êµ
| íŠ¹ì§• | vLLM | transformers |
|------|------|--------------|
| **ì¶”ë¡  ì†ë„** | 5-10ë°° ë¹ ë¦„ | ê¸°ì¤€ ì†ë„ |
| **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±** | PagedAttention | í‘œì¤€ ì–´í…ì…˜ |
| **ë°°ì¹˜ ì²˜ë¦¬** | ë™ì  ë°°ì¹˜ | ì •ì  ë°°ì¹˜ |
| **GPU í™œìš©ë¥ ** | 90%+ | 60-70% |
| **ë™ì‹œ ìš”ì²­** | ìˆ˜ì‹­ê°œ | ìˆ˜ê°œ |

### ê¶Œì¥ í•˜ë“œì›¨ì–´ ì‚¬ì–‘
- **ìµœì†Œ**: NVIDIA RTX 3080 (10GB VRAM)
- **ê¶Œì¥**: NVIDIA RTX 4090 (24GB VRAM)  
- **ìµœì **: NVIDIA A100 (40/80GB VRAM)
- **ë‹¤ì¤‘ GPU**: 2-4x RTX 4090 ë˜ëŠ” A100

## ğŸš¨ ë¬¸ì œ í•´ê²°

### vLLM ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# ì˜¬ë°”ë¥¸ CUDA ë²„ì „ìœ¼ë¡œ PyTorch ì¬ì„¤ì¹˜
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# vLLM ì¬ì„¤ì¹˜
pip install vllm --no-cache-dir
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
```python
# ì„¤ì • ì¡°ì •
analyzer = VLLMAnalyzer(
    gpu_memory_utilization=0.6,  # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê°ì†Œ
    max_model_len=2048,          # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê°ì†Œ
    enable_chunked_prefill=True  # ì²­í¬ ì²˜ë¦¬ í™œì„±í™”
)
```

### Fallback ëª¨ë“œ ì‚¬ìš©
```python
# vLLM ì‹¤íŒ¨ ì‹œ ìë™ fallback
analyzer = QwenVLMAnalyzer(use_vllm=True)  # vLLM ì‹œë„ í›„ transformersë¡œ fallback
```

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•

- **ì •í™•ë„**: ë²¡í„° + VLM í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ìœ¼ë¡œ ë†’ì€ ì •í™•ë„
- **ì†ë„**: ë³‘ë ¬ ì²˜ë¦¬ êµ¬ì¡°ë¡œ ë¹ ë¥¸ ë¶„ì„ ì‹œê°„
- **í™•ì¥ì„±**: LangGraph ê¸°ë°˜ ëª¨ë“ˆì‹ ì„¤ê³„
- **ì‹ ë¢°ì„±**: ë‹¤ì¤‘ ê²€ì¦ ë° ì˜¤ë¥˜ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

## ğŸ“ ê¸°ìˆ  ìŠ¤íƒ

- **AI ëª¨ë¸**: Qwen2.5-VL (Vision-Language Model)
- **ì›Œí¬í”Œë¡œìš°**: LangChain + LangGraph
- **ë²¡í„° ì²˜ë¦¬**: PyMuPDF + Shapely
- **ì»´í“¨íŒ…**: PyTorch + CUDA

## ğŸ“ˆ ê°œë°œ í˜„í™©

- âœ… í•µì‹¬ ë¶„ì„ ì—”ì§„ ì™„ì„±
- âœ… LangGraph ì›Œí¬í”Œë¡œìš° í†µí•©
- âœ… VLM ëª¨ë¸ ìµœì í™”
- ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘
- ğŸ“‹ ì‹¤ì‹œê°„ API ê°œë°œ ì˜ˆì •

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. ì´ìŠˆ ë“±ë¡
2. ê¸°ëŠ¥ ê°œë°œ
3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
4. í’€ ë¦¬í€˜ìŠ¤íŠ¸ ì œì¶œ

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ“ ì—°ë½ì²˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ë“±ë¡í•´ ì£¼ì„¸ìš”.

---

**ìµœê·¼ ì—…ë°ì´íŠ¸**: 2025ë…„ 6ì›” 11ì¼  
**ë²„ì „**: v1.0 (ë² íƒ€)  
**ìƒíƒœ**: í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ
