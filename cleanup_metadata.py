#!/usr/bin/env python3
"""
ë©”íƒ€ë°ì´í„° íŒŒì¼ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ _metadata.json íŒŒì¼ë“¤ì„ metadata í´ë”ë¡œ ì´ë™í•˜ê³  ì¤‘ë³µ ì œê±°
"""

import os
import shutil
from pathlib import Path
import json
from datetime import datetime

def cleanup_metadata_files():
    """ê¸°ì¡´ ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤ì„ metadata í´ë”ë¡œ ì •ë¦¬"""
    
    project_root = Path("uploads/01_í–‰ë³µë„ì‹œ 6-3ìƒí™œê¶ŒM3BL ì‹¤ì‹œì„¤ê³„ë„ë©´2ì°¨ ê±´ì¶•ë„ë©´/converted_dxf")
    
    if not project_root.exists():
        print(f"âŒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_root}")
        return
    
    print("ğŸ§¹ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì •ë¦¬ ì‹œì‘")
    print("=" * 50)
    
    # 1. ê¸°ì¡´ _metadata.json íŒŒì¼ë“¤ ì°¾ê¸°
    metadata_files = list(project_root.rglob("*_metadata.json"))
    
    print(f"ğŸ“ ë°œê²¬ëœ ë©”íƒ€ë°ì´í„° íŒŒì¼: {len(metadata_files)}ê°œ")
    
    moved_files = 0
    kept_files = 0
    removed_duplicates = 0
    
    for metadata_file in metadata_files:
        try:
            # metadata í´ë” ì•ˆì— ìˆëŠ” íŒŒì¼ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
            if "metadata" in metadata_file.parts:
                print(f"âœ… ìœ ì§€: {metadata_file.relative_to(project_root)}")
                kept_files += 1
                continue
            
            # í•´ë‹¹ ë””ë ‰í† ë¦¬ì— metadata í´ë” ìƒì„±
            metadata_dir = metadata_file.parent / "metadata"
            metadata_dir.mkdir(exist_ok=True)
            
            # ëª©ì ì§€ íŒŒì¼ ê²½ë¡œ
            dest_file = metadata_dir / metadata_file.name
            
            # ì´ë¯¸ metadata í´ë”ì— ê°™ì€ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if dest_file.exists():
                # ë‘ íŒŒì¼ì˜ ë‚´ìš© ë¹„êµ
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f1:
                        content1 = json.load(f1)
                    with open(dest_file, 'r', encoding='utf-8') as f2:
                        content2 = json.load(f2)
                    
                    # ì¶”ì¶œ ì‹œê°„ ì •ë³´ ì œì™¸í•˜ê³  ë¹„êµ
                    content1_compare = {k: v for k, v in content1.items() if k != 'extraction_info'}
                    content2_compare = {k: v for k, v in content2.items() if k != 'extraction_info'}
                    
                    if content1_compare == content2_compare:
                        # ë‚´ìš©ì´ ê°™ìœ¼ë©´ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
                        metadata_file.unlink()
                        print(f"ğŸ—‘ï¸  ì¤‘ë³µ ì œê±°: {metadata_file.relative_to(project_root)}")
                        removed_duplicates += 1
                    else:
                        # ë‚´ìš©ì´ ë‹¤ë¥´ë©´ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€í•˜ì—¬ ë°±ì—…
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        backup_name = f"{metadata_file.stem}_backup_{timestamp}.json"
                        backup_file = metadata_dir / backup_name
                        
                        shutil.move(metadata_file, backup_file)
                        print(f"ğŸ“¦ ë°±ì—… ì´ë™: {metadata_file.relative_to(project_root)} â†’ {backup_file.relative_to(project_root)}")
                        moved_files += 1
                        
                except Exception as e:
                    print(f"âš ï¸  íŒŒì¼ ë¹„êµ ì‹¤íŒ¨: {metadata_file.name} - {e}")
                    # ì˜¤ë¥˜ ì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€í•˜ì—¬ ì´ë™
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    backup_name = f"{metadata_file.stem}_old_{timestamp}.json"
                    backup_file = metadata_dir / backup_name
                    shutil.move(metadata_file, backup_file)
                    moved_files += 1
            else:
                # metadata í´ë”ì— íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ë™
                shutil.move(metadata_file, dest_file)
                print(f"ğŸ“ ì´ë™: {metadata_file.relative_to(project_root)} â†’ {dest_file.relative_to(project_root)}")
                moved_files += 1
                
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {metadata_file.name} - {e}")
    
    # 2. conversion_results.jsonì€ ìœ ì§€ (ë³€í™˜ ê²°ê³¼ ë¡œê·¸)
    conversion_file = project_root / "conversion_results.json"
    if conversion_file.exists():
        print(f"ğŸ“‹ ë³€í™˜ ë¡œê·¸ ìœ ì§€: {conversion_file.name}")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ ì •ë¦¬ ì™„ë£Œ")
    print(f"  â€¢ ì´ë™ëœ íŒŒì¼: {moved_files}ê°œ")
    print(f"  â€¢ ìœ ì§€ëœ íŒŒì¼: {kept_files}ê°œ")
    print(f"  â€¢ ì¤‘ë³µ ì œê±°: {removed_duplicates}ê°œ")
    
    # 3. ì •ë¦¬ëœ êµ¬ì¡° í™•ì¸
    print(f"\nğŸ“Š ì •ë¦¬ëœ metadata í´ë” êµ¬ì¡°:")
    metadata_dirs = list(project_root.rglob("metadata"))
    
    for metadata_dir in sorted(metadata_dirs):
        rel_path = metadata_dir.relative_to(project_root)
        json_files = list(metadata_dir.glob("*.json"))
        print(f"  ğŸ“ {rel_path}: {len(json_files)}ê°œ íŒŒì¼")
        
        for json_file in sorted(json_files)[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            print(f"    â€¢ {json_file.name}")
        if len(json_files) > 3:
            print(f"    â€¢ ... ì™¸ {len(json_files)-3}ê°œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì •ë¦¬ ë„êµ¬")
    print("=" * 60)
    
    try:
        cleanup_metadata_files()
        print("\nâœ… ì •ë¦¬ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"\nâŒ ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
